{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3zbLLaSGH6Z"
   },
   "source": [
    "## Лабораторная работа \"Введение в ML\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL3v975uGH6h"
   },
   "source": [
    "В этой лабораторной вы:\n",
    "\n",
    "- познакомитесь с базовыми библиотеками для работы с табличными данными — `numpy` и `pandas`\n",
    "- поближе посмотрите на простейшие задачи машинного обучения: классификацию и регрессию\n",
    "- попробуете несколько метрик и поймёте, почему выбор метрики это важно\n",
    "- обучите несколько простых моделей\n",
    "- увидите связь между сложностью модели и переобучением\n",
    "- убедитесь, что без данных всё тлен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad3nBqBSGH6j"
   },
   "source": [
    "Загрузка самых базовых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z8Iht5qhGH6l"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4W8Eq0sTGH6n"
   },
   "source": [
    "### [NumPy](https://numpy.org/doc/stable/user/index.html)\n",
    "\n",
    "С 1995 numeric, с 2006 NumPy — «Numerical Python extensions» или просто «NumPy»\n",
    "\n",
    "Возможности библиотеки NumPy:\n",
    "* работать с многомерными массивами (таблицами)\n",
    "* быстро вычислять математические функций на многомерных массивах\n",
    "\n",
    "Ядро пакета NumPy — объект [ndarray](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)\n",
    "\n",
    "**Важные отличия** между NumPy arrays и Python sequences:\n",
    "* NumPy array имеет фиксированную длину, которая определяется в момент его создания (в отличие от Python lists, которые могут расти динамически)\n",
    "* Элементы в NumPy array должны быть одного типа\n",
    "* Можно выполнять операции непосредственно над NumPy arrays\n",
    "\n",
    "**Скорость** NumPy достигается с помощью:\n",
    "* реализации на C\n",
    "* векторизации и броадкастинга (broadcasting). Например, произведение массивов совместимых форм.\n",
    "\n",
    "Теперь давайте разберёмся подробнее и сделаем что-нибудь приятное и полезное в `numpy`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS3UKcU6GH6o"
   },
   "source": [
    "### Индексация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqBzoEfvGH6p"
   },
   "source": [
    "В NumPy работает привычная индексация Python, ура! Включая использование отрицательных индексов и срезов (slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Anq_nSYTGH6q"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Замечание 1:</b> Индексы и срезы в многомерных массивах не нужно разделять квадратными скобками,\n",
    "т.е. вместо <b>matrix[i][j]</b> нужно использовать <b>matrix[i, j]</b>. Первое тоже работает, но сначала выдаёт строку i, потом элемент j в ней.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoHXSVIrGH6q"
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Замечание 2:</b> Срезы в NumPy создают view, а не копии, как в случае срезов встроенных последовательностей Python (string, tuple and list).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YJKxBB4dGH6s",
    "outputId": "61139b1d-46db-4f7f-d5bb-96b7c3f96284"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_matrix = np.ones((5, 5))\n",
    "ones_submatrix_view = ones_matrix[::3,::2] # creates a view, not copy\n",
    "#ones_matrix[::2,::2] = np.zeros((3, 3))\n",
    "ones_submatrix_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpEF1rp2GH6v"
   },
   "source": [
    "### Ссылка на Яндекс.Контест\n",
    "\n",
    "Решения и ответы в задачах, расположенных ниже, загружайте в контест на автоматическую проверку:\n",
    "https://new.contest.yandex.ru/60376/start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZpuxPhJGH6v"
   },
   "source": [
    "**1.** Реализуйте функцию, принимающую на вход два одномерных массива `first_array` и `second_array` и возвращающую матрицу, в которой первый массив соответствует первому столбцу матрицы, второй — второму.\n",
    "\n",
    "Вероятно первое, что приходит вам на ум, это конкатенация и транспонирование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hmQk1N6rGH6w"
   },
   "outputs": [],
   "source": [
    "def construct_matrix(first_array, second_array):\n",
    "    \"\"\"\n",
    "    Construct matrix from pair of arrays\n",
    "    :param first_array: first array\n",
    "    :param second_array: second array\n",
    "    :return: constructed matrix\n",
    "    \"\"\"\n",
    "    first_col = first_array.reshape(first_array.shape[0], 1)\n",
    "    sec_col = second_array.reshape(second_array.shape[0], 1)\n",
    "    return  np.hstack((first_col, sec_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TeFqyCz4GH6x",
    "outputId": "ecd0b7d3-7acf-40f2-878e-057d17136e8c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_matrix(np.array([1, 2, 3]),np.array([4, 5, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lP-lmcA2GH6y"
   },
   "source": [
    "(в скобках заметим, что конкатенировать можно vertically, horizontally, depth wise методами vstack, hstack, dstack по трём осям (0, 1 и 2, соотвественно), либо в общем случае `np.concatenate` — поиграйтесь ниже с прекрасным примером четырёхмерной точки, чтобы точно всё для себя понять)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xguxLJ0VGH6y",
    "outputId": "2f32df14-6f5d-4800-96b5-bb8fba9c9ec0"
   },
   "outputs": [],
   "source": [
    "p = np.arange(1).reshape([1, 1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z1JFw75eGH6y",
    "outputId": "16e3c894-2e0e-4a5a-edd4-7a974cfa43e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vstack:  (2, 1, 1, 1)\n",
      "hstack:  (1, 2, 1, 1)\n",
      "dstack:  (1, 1, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"vstack: \", np.vstack((p, p)).shape)\n",
    "print(\"hstack: \", np.hstack((p, p)).shape)\n",
    "print(\"dstack: \", np.dstack((p, p)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cvbthbDDGH6z",
    "outputId": "d89430e5-8c64-4b5f-f2b3-4343f4c659ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((p, p), axis=3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5GkuWwaGH60"
   },
   "source": [
    "Но, поскольку операция транспонирования [делает массив non-contiguous](https://numpy.org/doc/stable/user/basics.copies.html#other-operations), мы в этой задаче **запретим** ей пользоваться и порекомедуем воспользоваться, например, методом [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3ce_o75GH61"
   },
   "source": [
    "**2.** Реализуйте функцию, принимающую на вход массив целых неотрицательных чисел `nums` и возвращающую самый частый элемент массива."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XZysMovaGH61"
   },
   "outputs": [],
   "source": [
    "def most_frequent(nums):\n",
    "    \"\"\"\n",
    "    Find the most frequent value in an array\n",
    "    :param nums: array of ints\n",
    "    :return: the most frequent value\n",
    "    \"\"\"\n",
    "    counter = {}\n",
    "    for i in nums:\n",
    "        if i in counter.keys():\n",
    "            counter[i] += 1\n",
    "        else:\n",
    "            counter[i] = 1\n",
    "    max_key = max(counter, key=counter.get)\n",
    "    return max_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6kjITZMGH62"
   },
   "source": [
    "### Переходим к работе с данными\n",
    "\n",
    "Прежде всего, загрузим данные и сделаем из них красивые pandas-таблички. Они взяты из параллели RecSys соревнования https://yandex.ru/cup/ml/. Но мы будем иметь дело не со всеми данными, а только с их частью. Данные у нас будут про заведения общественного питания (больше бюрократический терминологии!)\n",
    "\n",
    "Файлы с данными можно найти [здесь](https://disk.yandex.ru/d/YWvCNRQMb7QSQA).\n",
    "\n",
    "Задачей будет **предсказание среднего чека** (average_bill) по некоторым другим свойствам заведения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yJPF3OclGH62"
   },
   "outputs": [],
   "source": [
    "base = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uzDIu6uXGH62"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(base + 'organisations.csv')\n",
    "features = pd.read_csv(base + 'features.csv')\n",
    "rubrics = pd.read_csv(base + 'rubrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-AwDM7bGH63"
   },
   "source": [
    "В основном мы будем работать с табличкой `data`; остальное вам может пригодиться, если вы захотите знать, какое содержание стоит за кодами признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hrvEN_3GH63"
   },
   "source": [
    "## Изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI9YQMuCGH63"
   },
   "source": [
    "Посмотрите на данные. В этом вам поможет метод ``head`` pandas-таблички."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VA_0DG29GH64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_id</th>\n",
       "      <th>city</th>\n",
       "      <th>average_bill</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics_id</th>\n",
       "      <th>features_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15903868628669802651</td>\n",
       "      <td>msk</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4.270968</td>\n",
       "      <td>30776 30774</td>\n",
       "      <td>3501685156 3501779478 20422 3502045016 3502045...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16076540698036998306</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>30771</td>\n",
       "      <td>1509 1082283206 273469383 10462 11617 35017794...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8129364761615040323</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>31495</td>\n",
       "      <td>10462 11177 11617 11629 1416 1018 11704 11867 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15262729117594253452</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.538813</td>\n",
       "      <td>30776 30770</td>\n",
       "      <td>3501618484 2020795524 11629 11617 1018 11704 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13418544315327784420</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.409091</td>\n",
       "      <td>31495</td>\n",
       "      <td>11617 10462 11177 1416 11867 3501744275 20282 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68334</th>\n",
       "      <td>4379286080707082909</td>\n",
       "      <td>msk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>30774</td>\n",
       "      <td>1018 1415 10462 11629 11867 20422 20424 118949...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68335</th>\n",
       "      <td>7916477189329738565</td>\n",
       "      <td>msk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.894231</td>\n",
       "      <td>30776</td>\n",
       "      <td>11634 11629 3501481353 11177 3501773763 11867 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68336</th>\n",
       "      <td>12358902585434046825</td>\n",
       "      <td>msk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>30774</td>\n",
       "      <td>20422 11867 246 3501754799 3501779478 12048 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68337</th>\n",
       "      <td>1712093598996183140</td>\n",
       "      <td>spb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30771 30774</td>\n",
       "      <td>3491142672 3501481353 11867 20422 273469383 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68338</th>\n",
       "      <td>125079240973229511</td>\n",
       "      <td>spb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>30776</td>\n",
       "      <td>3501498189 3501509030 3501498184 12309 20422 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68339 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     org_id city  average_bill    rating   rubrics_id  \\\n",
       "0      15903868628669802651  msk        1500.0  4.270968  30776 30774   \n",
       "1      16076540698036998306  msk         500.0  4.375000        30771   \n",
       "2       8129364761615040323  msk         500.0  4.000000        31495   \n",
       "3      15262729117594253452  msk         500.0  4.538813  30776 30770   \n",
       "4      13418544315327784420  msk         500.0  4.409091        31495   \n",
       "...                     ...  ...           ...       ...          ...   \n",
       "68334   4379286080707082909  msk           NaN  3.812500        30774   \n",
       "68335   7916477189329738565  msk           NaN  4.894231        30776   \n",
       "68336  12358902585434046825  msk           NaN  4.156250        30774   \n",
       "68337   1712093598996183140  spb           NaN       NaN  30771 30774   \n",
       "68338    125079240973229511  spb           NaN  4.633333        30776   \n",
       "\n",
       "                                             features_id  \n",
       "0      3501685156 3501779478 20422 3502045016 3502045...  \n",
       "1      1509 1082283206 273469383 10462 11617 35017794...  \n",
       "2      10462 11177 11617 11629 1416 1018 11704 11867 ...  \n",
       "3      3501618484 2020795524 11629 11617 1018 11704 2...  \n",
       "4      11617 10462 11177 1416 11867 3501744275 20282 ...  \n",
       "...                                                  ...  \n",
       "68334  1018 1415 10462 11629 11867 20422 20424 118949...  \n",
       "68335  11634 11629 3501481353 11177 3501773763 11867 ...  \n",
       "68336  20422 11867 246 3501754799 3501779478 12048 35...  \n",
       "68337  3491142672 3501481353 11867 20422 273469383 11...  \n",
       "68338  3501498189 3501509030 3501498184 12309 20422 3...  \n",
       "\n",
       "[68339 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN9kZbURGH64"
   },
   "source": [
    "Полезно посмотреть внимательнее на то, с какими признаками нам предстоит работать.\n",
    "\n",
    "* **org_id** вам не понадобится;\n",
    "* **city** - город, в котором находится заведение (``msk`` или ``spb``);\n",
    "* **average_bill** - средний чек в заведении - он будет нашим таргетом;\n",
    "* **rating** - рейтинг заведения;\n",
    "* **rubrics_id** - тип заведения (или несколько типов). Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``rubrics``\n",
    "* **features_id** - набор неких фичей заведения. Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``features``\n",
    "\n",
    "Обратите внимание, что **rubrics_id** и **features_id** - это не списки, а разделённые пробелами строки. Когда вам захочется работать с отдельными фичами из мешка фичей для данного заведения, вам придётся всё-таки превратить их в списки (здесь поможет метод `split` для строк)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0IJIWz3GH64"
   },
   "source": [
    "Чтобы быстро восстанавливать по рубрикам и фичам их нормальные названия, сделайте словари вида ``код_фичи:название_фичи``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8KwKEKr7GH65"
   },
   "outputs": [],
   "source": [
    "rubric_dict = rubrics.set_index('rubric_id')['rubric_name'].to_dict()\n",
    "features_dict = features.set_index('feature_id')['feature_name'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNd4PkyQGH65"
   },
   "source": [
    "Посмотрим, какими бывают типы заведений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8WhaPPEeGH65",
    "outputId": "aaf9cc8c-64ae-4bac-d8f8-6dd4d03033d8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30519: 'Булочная, пекарня',\n",
       " 30770: 'Бар, паб',\n",
       " 30771: 'Быстрое питание',\n",
       " 30774: 'Кафе',\n",
       " 30775: 'Пиццерия',\n",
       " 30776: 'Ресторан',\n",
       " 30777: 'Столовая',\n",
       " 31286: 'Спортбар',\n",
       " 31350: 'Кондитерская',\n",
       " 31375: 'Суши-бар',\n",
       " 31401: 'Кальян-бар',\n",
       " 31495: 'Кофейня',\n",
       " 3108292683: 'Бар безалкогольных напитков',\n",
       " 3501514558: 'Фудкорт',\n",
       " 3501750896: 'Кофе с собой'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_bill\n",
       "500.0       22329\n",
       "1000.0       5482\n",
       "1500.0       2696\n",
       "2000.0       1184\n",
       "2500.0        445\n",
       "            ...  \n",
       "18500.0         1\n",
       "117000.0        1\n",
       "30000.0         1\n",
       "203500.0        1\n",
       "101500.0        1\n",
       "Name: count, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['average_bill'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA6Bm_8EGH66"
   },
   "source": [
    "Мы что-то поняли про признаки, которыми нам предстоит пользоваться. Теперь время посмотреть на таргет. Вооружившись функциями ``hist`` и ``scatter`` из библиотеки ``matplotlib``, а также методом ``isna`` для pandas-таблиц разберитесь, какие значения принимают таргеты, есть ли там там выбросы, пропуски или ещё какие-то проблемы.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "    <ol>\n",
    "      <li>Среди таргетов довольно много пропусков;</li>\n",
    "      <li>Все таргеты - это числа, кратные 500;</li>\n",
    "      <li>Есть какие-то адские значения, превышающие 100 000 (видимо, выбросы);</li>\n",
    "      <li>В целом, число ресторанов с данным средним чеком быстро падает с ростом среднего чека. Для средних чеков, больших 2500, заведений уже совсем мало. Примерно у 2/3 заведений средний чек 500.</li>\n",
    "    </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6bg-kmIGH66",
    "outputId": "69beeb66-b7aa-4905-bc73-59a6ab27edf3",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trfl5F_4GH66"
   },
   "source": [
    "**Базовая очистка данных**\n",
    "\n",
    "Раз есть треш, давайте чистить данные.\n",
    "\n",
    "С пропусками можно бороться по-разному (даже и с пропусками в таргете), но пока мы сделаем самую простую вещь: дропнем все заведения, для которых мы не знаем средний чек.\n",
    "\n",
    "Уберите из них все заведения, у которых средний чек неизвестен или превышает 2500. Пока есть опасение, что их слишком мало, чтобы мы смогли обучить на них что-нибудь.\n",
    "\n",
    "**3. Введите в Контест количество заведений, которое у вас получилось после очистки**.\n",
    "\n",
    "Дальше мы будем работать с очищенными данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OxIkRsA1GH67"
   },
   "outputs": [],
   "source": [
    "data = data.dropna(subset='average_bill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['average_bill'] <= 2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32136, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsNzGAp1GH67"
   },
   "source": [
    "**4. Посчитайте и введите в Контест разность между средними арифметическими average_bill в кафе Москвы и Санкт-Петербурга. Округлите ответ до целого.**\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Небольшая подсказка</summary>\n",
    "  Примените часто используемый метод groupby.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gLdl3zVCGH67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "msk    781.080794\n",
       "spb    638.677107\n",
       "Name: average_bill, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['rubrics_id'].str.contains('30774')].groupby(['city'])['average_bill'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qncnmi8bGH7F"
   },
   "source": [
    "Давайте ещё немного поизучаем данные. Ответьте на вопросы:\n",
    "\n",
    "1. Есть ли разница между средними чеками в Москве и Санкт-Петербурге?\n",
    "2. Коррелирует ли средний чек с рейтингом?\n",
    "3. Есть ли разница в среднем чеке между ресторанами и пабами (см. соответствующие типы из ``rubrics``)?\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "    <ol>\n",
    "      <li>В целом, да. Вы могли бы сравнить средние (в Москве больше) или медианы (они равны, потому что уж больно много где средний чек 500). Этого, конечно, мало для того, чтобы сделать вывод. Нужно проверять какие-то статические критерии, которые изучаются в курсе по статистике. Не будем останавливаться на этом подробно. Поскольку данные совсем не нормальные, никакой t-тест не сработает; мы бы предложили использовать критерий Манна-Уитни (см. википедию и функцию mannwhitneyu из библиотеки scipy.stats).</li>\n",
    "      <li>Какая-то корреляция между ними есть но уж больно неубедительная (рекомендуем построим на одном графике boxplot рейтинга по каждому значению среднего чека для визуализации). Конечно, дна становится меньше с ростом среднего чека, но, видимо, в предсказании это особо не используешь;</li>\n",
    "      <li>Несомненно, в ресторанах средний чек выше. Это и невооружённым глазом видно, и с помощью критерия Манна-Уитни можно проверить.</li>\n",
    "    </ol>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIKTOR\\AppData\\Local\\Temp\\ipykernel_14076\\3537067355.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data.groupby(['city'])['average_bill'].mean()[0] - data.groupby(['city'])['average_bill'].mean()[1]\n",
      "C:\\Users\\VIKTOR\\AppData\\Local\\Temp\\ipykernel_14076\\3537067355.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data.groupby(['city'])['average_bill'].mean()[0] - data.groupby(['city'])['average_bill'].mean()[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116.43756751957676"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['city'])['average_bill'].mean()[0] - data.groupby(['city'])['average_bill'].mean()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VIKTOR\\AppData\\Local\\Temp\\ipykernel_14076\\2943152567.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped = data.groupby('rating_bins')['average_bill'].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "bins = np.arange(0, 5.1, 0.1)\n",
    "data['rating_bins'] = pd.cut(data['rating'], bins=bins)\n",
    "\n",
    "grouped = data.groupby('rating_bins')['average_bill'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b4000c1cf0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(grouped['rating_bins'].apply(lambda x: x.mid), grouped['average_bill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181.2283246610557"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['rubrics_id'].str.contains('30776'), 'average_bill'].mean() - data.loc[data['rubrics_id'].str.contains('30770'), 'average_bill'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATY5075lGH7F"
   },
   "source": [
    "## Формулируем задачу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znpEgJGIGH7F"
   },
   "source": [
    "Прежде, чем решать задачу, её надо сформулировать.\n",
    "\n",
    "**Вопрос первый**: это классификация или регрессия? Подумайте над этим.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "    Ответ не столь однозначен, как хотелось бы. С одной стороны, таргет принимает всего четыре значения, и потому это может быть классификацией с 4 классами. С другой стороны, таргеты - это не абстрактные \"треугольник\", \"круг\", \"квадрат\", а вещественные числа, и когда мы вместо 500 предсказываем 2500, это явно хуже, чем вместо 1500 предсказать 2000. В целом, задачу можно решать и так, и так; мы будем смотреть на метрики обеих задач.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaVuazxsGH7G"
   },
   "source": [
    "**Вопрос второй**: какие метрики мы будем использовать для оценки качества решения? Какие метрики вы предложили бы для этой задачи как для задачи классификации? А для этой задачи, как для задачи регрессии?\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "    \n",
    "    Начнём с классификации. Метрика accuracy не очень хороша из-за несбалансированности классов. Действительно, классификатор, который всегда говорит 500, будет иметь accuracy примерно 0.66, хотя это никак не отражает практическую ценность модели. Как мы увидим, самая большая проблема будет заключаться в том, чтобы научиться выделять заведения с большими чеками, а их меньше всего и в accuracy они вносят самый маленький вклад. Есть разные способы с этим бороться, один -- использовать sklearn.metrics.balanced_accuracy_score. Его идея, грубо говоря, в том, чтобы по каждому классу найти, какая доля объектов этого класса правильно классифицирована, а потом эти доли усреднить. Тогда у бессмысленного классификатора, который всем ставит 500, будет скор 1/5 (ведь классов 5), а чтобы получить прежние 2/3, нужно будет научиться в каждом классе правильно ставить хотя бы 2/3 меток.    \n",
    "    \n",
    "    Теперь что касается регрессии. Основых метрики две - MSE и MAE. Из первой стоит извлекать корень, чтобы получать интерпретируемые человеком значения, а вторая менее агрессивна к выбросам (впрочем, выбросов тут уже нет, мы их все выкинули). Без дополнительной информации не очень понятно, какую выбирать, можно брать любую. А выбирать надо: ведь даже банальные модели \"предсказывай всегда среднее\" и \"предсказывай всегда медиану\" будут по-разному ранжироваться этими метриками.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vs-jkCj-GH7G"
   },
   "source": [
    "**Вопрос третий**: а не взять ли нам какую-нибудь более экзотическую метрику? Например, MAPE (определение в учебнике в главе про оценку качества моделей). А как вам такое соображение: допустим, заказчик говорит, что пользователи будут расстраиваться, только если мы завысили средний чек - так давайте поправим MSE или MAE, обнуляя те слагаемые, для которых предсказанный таргет меньше истинного. Вот это хорошая метрика или нет?\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "    \n",
    "    Что касается MAPE, у нас нет тех проблем, с которой она борется. Вот если бы у нас были средние чеки от 500 до миллиона, мы бы столкнулись с ситуацией, что большие ошибки для больших чеков доминировали бы в сумме для MSE и MAE (500 вместо 1000 меркнет по сравнению с 500к вместо миллиона). Говоря поэтически, мы бы оптимизировали модель для миллионеров, забыв про простых трудяг. И было бы логично перейти от парадигмы \"ошибаемся на 500 рублей\" к парадигме \"ошибаемся на 50%\". Но у нас все таргеты примерно одного порядка, MAPE нам особо ни к чему.\n",
    "    \n",
    "    Вторая метрика коварна тем, что её можно \"накрутить\" безо всякой пользы для дела. А именно, модель, которая всегда предсказывает средний чек в миллион, была бы идеальна. Но все бы расстраивались и не ходили есть. Другое дело, что можно ввести разные веса для ошибок в большую и в меньшую сторону, но опять же - пока нет показаний к тому, что это нужно.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCjV_SoAGH7G"
   },
   "source": [
    "## Применяем ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqkvcLSPGH7G"
   },
   "source": [
    "Теперь время разбить данные на обучающую и тестовую выборку. Делается это с помощью функции ``train_test_split`` из пакета ``sklearn``. При этом очень важно сделать две вещи:\n",
    "\n",
    "* Зафиксировать ``random_state=42`` (да, именно этот, а то ваши модели могут не зайти в Контест), чтобы всё, что мы делаем, было воспроизводимо (иначе от перезапуска к перезапуску числа могут меняться, и мы не будем понимать, из-за чего это происходит).\n",
    "* Сделать стратификацию по таргету. В противном случае у нас в трейне и тесте могут оказаться разные пропорции классов (обычно особенно страдают мало представленные классы), что неутешительно скажется на результате.\n",
    "\n",
    "**Обратите внимание**, что если вы побьёте выборку на train и test по-другому, ваши результаты могут не зайти в контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AF2IVpOjGH7H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "clean_data_train, clean_data_test = train_test_split(\n",
    "    data, stratify=data['average_bill'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S161veFJGH7H"
   },
   "source": [
    "Теперь нам нужен **бейзлайн** - очень простая модель, с которой мы в дальнейшем будем сравниваться.\n",
    "\n",
    "Поскольку мы ещё не знаем никаких умных классов моделей, все модели мы будем писать руками. А именно, мы напишем две простых модели на основе ``sklearn.baseRegressorMixin`` и ``sklearn.base.ClassifierMixin`` (посмотрите примеры в документации sklearn и сделайте так же):\n",
    "\n",
    "* Модель для задачи регрессии, которая для всех заведений предсказывает одно число — среднее значение среднего чека;\n",
    "* Модель для задачи классификации, которая для всех заведений предсказывает один класс — самый частый класс (ироничным образом он в данном случае совпадает с медианой).\n",
    "\n",
    "**Важно!** Мы будем много раз повторять вам мантру о том, что **информация из тестовой выборки не должна протекать в процесс обучения**. Так вот, и среднее, и самый частый класс вы должны считать именно на обучающей выборке!\n",
    "\n",
    "**5 и 6. Напишите эти две модели и сдайте в Контест**. В процессе проверки модели будут и обучаться, и предсказывать.\n",
    "\n",
    "Заметим, что для этих моделей нам вообще не нужны какие-то \"фичи\"; мы работаем только с таргетом.\n",
    "\n",
    "У каждой модели есть (как минимум) два метода: `fit` (обучает модель по фичам `X` и таргету `y`) `predict` (предсказывает по фичам `X`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lLz_sxtUGH7H"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.base import RegressorMixin\n",
    "\n",
    "class MeanRegressor(RegressorMixin):\n",
    "    # Predicts the mean of y_train\n",
    "    def fit(self, X=None, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array like, shape = (n_samples, n_features)\n",
    "        Training data features\n",
    "        y : array like, shape = (_samples,)\n",
    "        Training data targets\n",
    "        \"\"\"\n",
    "        self.res = y.mean()\n",
    "        return None\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array like, shape = (n_samples, n_features)\n",
    "        Data to predict\n",
    "        \"\"\"\n",
    "        return self.res\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "class MostFrequentClassifier(ClassifierMixin):\n",
    "    def fit(self, X=None, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array like, shape = (n_samples, n_features)\n",
    "            Training data features (ignored in this classifier)\n",
    "        y : array like, shape = (n_samples,)\n",
    "            Training data targets\n",
    "        \"\"\"\n",
    "        self.most_frequent_ = mode(y).mode\n",
    "        return None\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array like, shape = (n_samples, n_features)\n",
    "            Data to predict (features are ignored)\n",
    "        \"\"\"\n",
    "        return self.most_frequent_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo2pNhVoGH7I"
   },
   "source": [
    "Обучим наши модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "arXlaGnTGH7I"
   },
   "outputs": [],
   "source": [
    "reg = MeanRegressor()\n",
    "reg.fit(y=clean_data_train['average_bill'])\n",
    "\n",
    "clf = MostFrequentClassifier()\n",
    "clf.fit(y=clean_data_train['average_bill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred_clf = clf.predict()\n",
    "pred_reg = reg.predict()\n",
    "num = clean_data_test.shape[0]\n",
    "balanced_accuracy_score(clean_data_test['average_bill'], np.full(num, pred_clf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "514.7517402382093"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(clean_data_test['average_bill'], np.full(num, pred_clf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "448.7143889551622"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(clean_data_test['average_bill'], np.full(num, pred_reg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJG8x0tmGH7I"
   },
   "source": [
    "Обучите модели и оцените их качество на тестовой выборке. В качестве метрик возьмём RMSE (``np.sqrt`` от ``sklearn.metrics.mean_squared_error``) и ``sklearn.metrics.balanced_accuracy_score``.\n",
    "\n",
    "Для регрессионной модели имеет смысл считать только RMSE (значения будут не кратны 500, точно мы угадывать не будем никогда), а вот для классификационной можно найти обе метрики. Сделайте это. Какая модель оказалась лучше по RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvZwp54sGH7J"
   },
   "source": [
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда</summary>\n",
    "    \n",
    "  Казалось бы, регрессор никогда не угадывает, но он в каком-то смысле лучше классификатора - справедливо ли это? Возможно. Несуществующий пользователь модели вряд ли будет задавать вопросы \"почему средний чек не кратен 500?\" Ну, выдали около 800 - ок, понятно.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-1-O9GyGH7J"
   },
   "source": [
    "## Усложнение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGWgxl0VGH7J"
   },
   "source": [
    "Бейзлайны будут нашей отправной точкой. Строя дальнейшие модели, мы будем спрашивать себя: получилось ли лучше бейзлайна? Если нет или если не особо, то в чём смысл усложнения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w3DkuuFGH7K"
   },
   "source": [
    "Начнём с использования фичи ``city``. Мы уже видели, что в разных городах и средние чеки разные. Легко проверить, что *медиана* средних чеков всё же одна и та же и в Москве, и в Санкт-Петербурге (ох уж этот вездесущий средний чек 500!), поэтому с классификатором мы ничего не сделаем. Но вот регрессор можно попробовать починить.\n",
    "\n",
    "**7. Напишите регрессор, для каждого заведения предсказывающий среднее значение в том же городе (на обучающей выборке, конечно) и сдайте его в Контест**. Вам может помочь то, что булевы `pandas` и `numpy` столбцы можно умножать на численные — в такой ситуации False работает, как ноль, а True как единица."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ZULQVPe2GH7K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import RegressorMixin, BaseEstimator\n",
    "\n",
    "class CityMeanRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # Преобразуем X в DataFrame, если это ndarray\n",
    "\n",
    "        if isinstance(X, np.ndarray):\n",
    "\n",
    "            X = pd.DataFrame(X, columns=[\"city\"])\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "\n",
    "            raise ValueError(\"X должен быть pandas DataFrame или numpy.ndarray\")\n",
    "\n",
    "        if \"city\" not in X.columns:\n",
    "\n",
    "            raise ValueError(\"В X должна быть колонка 'city'\")\n",
    "\n",
    "        # Вычисляем среднее значение целевой переменной для каждого города\n",
    "\n",
    "        self.city_means_ = pd.Series(y).groupby(X[\"city\"]).mean()\n",
    "\n",
    "        self.global_mean_ = np.mean(y)  # На случай, если город неизвестен\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # Преобразуем X в DataFrame, если это ndarray\n",
    "\n",
    "        if isinstance(X, np.ndarray):\n",
    "\n",
    "            X = pd.DataFrame(X, columns=[\"city\"])\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "\n",
    "            raise ValueError(\"X должен быть pandas DataFrame или numpy.ndarray\")\n",
    "\n",
    "        if \"city\" not in X.columns:\n",
    "\n",
    "            raise ValueError(\"В X должна быть колонка 'city'\")\n",
    "\n",
    "        # Прогнозируем среднее значение по городу, если город известен\n",
    "\n",
    "        predictions = X[\"city\"].map(self.city_means_).fillna(self.global_mean_)\n",
    "\n",
    "        return predictions.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CityMeanRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CityMeanRegressor</label><div class=\"sk-toggleable__content\"><pre>CityMeanRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CityMeanRegressor()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = CityMeanRegressor()\n",
    "reg.fit(y=clean_data_train['average_bill'], X=clean_data_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EeFGk24GH7K"
   },
   "source": [
    "Обучите регрессор и сравните его по метрике RMSE с бейзлайнами. Получилось ли улучшить метрику?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "445.1063281403263"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(clean_data_test['average_bill'], reg.predict(clean_data_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jROycei1GH7L"
   },
   "source": [
    "Лучше стало, но, правда, не очень сильно. В этот момент очень важно не просто радовать руководителя приростом в третьем знаке, но и думать о том, что происходит.\n",
    "\n",
    "Средний средний чек по Москве равен 793, в Санкт-Петербурге - 676, а в целом - 752 рубля. MSE, увы, не поможет вам ответить на вопрос, стало ли лучше пользователю, если вы ему вместо 752 рублей назвали 793. Здесь вскрывается весьма существенный порок MSE в этой задаче. Дело в том, что наш изначальный таргет делит заведения на некоторые \"ценовые категории\", и различие в средних чеках 500 и 1000 в самом деле существенно. Наверное, мы хотели бы как раз правильно предсказывать ценовые категории. Но MSE не очень помогает нам об этом судить. Дальше мы ещё подумаем, как это исправить.\n",
    "\n",
    "В любом случае, несмотря на улучшение метрики, мы пока не можем судить, стало ли по жизни лучше от усложнения модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEQ9eOoWGH7L"
   },
   "source": [
    "Поручинившись немного, возьмём на вооружение другую идею. Давайте использовать типы заведений!\n",
    "\n",
    "Но с типами есть некоторая проблема: в столбце ``rubrics_id`` не всегда один идентификатор, часто их несколько, и всего комбинаций довольно много. Чтобы не возиться с малочисленными типами, давайте сольём их в один безликий ``other``.\n",
    "\n",
    "Итак, добавьте в обучающие и тестовые данные столбец ``modified_rubrics``, в котором будет то же, что и в ``rubrics_id``, если соответствующая комбинация рубрик содержит хотя бы 100 заведений из обучающей (!) выборки, и строка ``other`` в противном случае.\n",
    "\n",
    "Здесь вам поможет контейнер ``Counter`` из библиотеки ``collections``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZXhpBjnGH7L"
   },
   "source": [
    "Теперь настало время написать могучий классификатор, который по заведению предсказывает медиану средних чеков среди тех в обучающей выборке, у которых с ним одинаковые `modified_rubrics` и город (вы спросите, почему медиану, а не самый частый -- спишем это на вдохновение; самый частый тоже можно брать - но медиана работает лучше).\n",
    "\n",
    "**8. Напишите классификатор и сдайте в Контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eTfcwh5dGH7M"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "class RubricCityMedianClassifier(ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()  # Создаем копию X, чтобы избежать модификаций оригинального DataFrame\n",
    "        self.count = Counter(X['rubrics_id'])\n",
    "        \n",
    "        # Создаем маппинг, где rubrics с частотой < 100 заменяются на 'other'\n",
    "        self.rubric_mapping = {\n",
    "            rubric: 'other' if count < 100 else rubric \n",
    "            for rubric, count in self.count.items()\n",
    "        }\n",
    "        \n",
    "        # Добавляем новую колонку с модифицированными rubrics\n",
    "        X['modified_rubrics'] = X['rubrics_id'].map(self.rubric_mapping)\n",
    "        \n",
    "        # Добавляем колонку с target значениями\n",
    "        X['average_bill'] = y\n",
    "        \n",
    "        # Группируем по city и modified_rubrics, считая медиану\n",
    "        self.res_dict = X.groupby(['city', 'modified_rubrics'])['average_bill'].median().to_dict()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.copy()  # Избегаем модификации оригинального DataFrame\n",
    "        # Применяем маппинг к rubrics_id\n",
    "        X['modified_rubrics'] = X['rubrics_id'].map(self.rubric_mapping)\n",
    "        a = set(X['rubrics_id'])\n",
    "        b = set(self.rubric_mapping.keys())\n",
    "        rubrics_to_mark_as_other = a - b\n",
    "        X['modified_rubrics'] = np.where(\n",
    "            X['rubrics_id'].isin(rubrics_to_mark_as_other),\n",
    "            'other',\n",
    "            X['modified_rubrics']\n",
    "        )\n",
    "        # Вычисляем предсказание для каждой строки\n",
    "        res = X.apply(\n",
    "            lambda row: self.res_dict.get((row['city'], row['modified_rubrics']), None),\n",
    "            axis=1\n",
    "        )\n",
    "        return res.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RubricCityMedianClassifier at 0x1b400272650>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RubricCityMedianClassifier()\n",
    "clf.fit(clean_data_train, clean_data_train['average_bill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbgjbwgkGH7M"
   },
   "source": [
    "Сравните обученный классификатор по метрикам RMSE и balanced_accuracy_score с нашими бейзлайнами. Получилось ли улучшить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30552511833185647"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(clean_data_test['average_bill'], clf.predict(clean_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "393.96675836287915"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(clean_data_test['average_bill'], clf.predict(clean_data_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMjsnCnQGH7M"
   },
   "source": [
    "Обратите внимание что рост accuracy по сравнению с бейзлайном при этом на порядок меньше:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2cF0I-CGH7M"
   },
   "source": [
    "accuracy_score\n",
    "\n",
    "Predict most frequent:  0.6947666195190948\n",
    "\n",
    "Predict by rubric and city:  0.7095709570957096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_bill\n",
       "500.0     7368\n",
       "1000.0    1809\n",
       "1500.0     890\n",
       "2000.0     391\n",
       "2500.0     147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_test['average_bill'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_test['predicted_average_bill'] = clf.predict(clean_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_id</th>\n",
       "      <th>city</th>\n",
       "      <th>average_bill</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics_id</th>\n",
       "      <th>features_id</th>\n",
       "      <th>rating_bins</th>\n",
       "      <th>predicted_average_bill</th>\n",
       "      <th>is_true_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65841</th>\n",
       "      <td>14385912302763770021</td>\n",
       "      <td>spb</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.748444</td>\n",
       "      <td>30776 30770 31401</td>\n",
       "      <td>11177 3501618484 10462 3501481355 1509 1416 20...</td>\n",
       "      <td>(4.7, 4.8]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48882</th>\n",
       "      <td>16695436192794975203</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.793758</td>\n",
       "      <td>30771</td>\n",
       "      <td>3501744275 273469383 3501513153 11617 10462 11...</td>\n",
       "      <td>(3.7, 3.8]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33711</th>\n",
       "      <td>11841431940065207518</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.606557</td>\n",
       "      <td>30771 30777</td>\n",
       "      <td>3501773763 3501744275 3501773764 3501618484 15...</td>\n",
       "      <td>(3.6, 3.7]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33544</th>\n",
       "      <td>16028521499441205186</td>\n",
       "      <td>msk</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.683841</td>\n",
       "      <td>30776</td>\n",
       "      <td>3501618484 20422 1082283206 11704 11629 21247 ...</td>\n",
       "      <td>(4.6, 4.7]</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>12477116204055673498</td>\n",
       "      <td>spb</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.165394</td>\n",
       "      <td>30776 31401 30770</td>\n",
       "      <td>1524 246 11704 1018 3501618484 2020795524 2124...</td>\n",
       "      <td>(4.1, 4.2]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55337</th>\n",
       "      <td>9041226080397910513</td>\n",
       "      <td>msk</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>4.408108</td>\n",
       "      <td>30776</td>\n",
       "      <td>11629 11704 10462 11617 3501744275 20424 35017...</td>\n",
       "      <td>(4.4, 4.5]</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64048</th>\n",
       "      <td>14998683880343589209</td>\n",
       "      <td>msk</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>30776</td>\n",
       "      <td>273469383 20424 20422 246 1416 11867 11629 104...</td>\n",
       "      <td>(3.5, 3.6]</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>1621254442333414922</td>\n",
       "      <td>msk</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.402516</td>\n",
       "      <td>30776</td>\n",
       "      <td>273469383 21247 11867 1082283206 20422 246 101...</td>\n",
       "      <td>(4.4, 4.5]</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40089</th>\n",
       "      <td>5620614742257813954</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30771</td>\n",
       "      <td>11704 1018 273469383 10462 20422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>11624301828012509826</td>\n",
       "      <td>spb</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>30774</td>\n",
       "      <td>246 11867 1018 1415 1416 1524 10462 1509 11617...</td>\n",
       "      <td>(4.2, 4.3]</td>\n",
       "      <td>500.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     org_id city  average_bill    rating         rubrics_id  \\\n",
       "65841  14385912302763770021  spb        1000.0  4.748444  30776 30770 31401   \n",
       "48882  16695436192794975203  msk         500.0  3.793758              30771   \n",
       "33711  11841431940065207518  msk         500.0  3.606557        30771 30777   \n",
       "33544  16028521499441205186  msk        2000.0  4.683841              30776   \n",
       "35293  12477116204055673498  spb         500.0  4.165394  30776 31401 30770   \n",
       "...                     ...  ...           ...       ...                ...   \n",
       "55337   9041226080397910513  msk        2500.0  4.408108              30776   \n",
       "64048  14998683880343589209  msk        1000.0  3.555556              30776   \n",
       "22010   1621254442333414922  msk        2000.0  4.402516              30776   \n",
       "40089   5620614742257813954  msk         500.0       NaN              30771   \n",
       "32180  11624301828012509826  spb         500.0  4.250000              30774   \n",
       "\n",
       "                                             features_id rating_bins  \\\n",
       "65841  11177 3501618484 10462 3501481355 1509 1416 20...  (4.7, 4.8]   \n",
       "48882  3501744275 273469383 3501513153 11617 10462 11...  (3.7, 3.8]   \n",
       "33711  3501773763 3501744275 3501773764 3501618484 15...  (3.6, 3.7]   \n",
       "33544  3501618484 20422 1082283206 11704 11629 21247 ...  (4.6, 4.7]   \n",
       "35293  1524 246 11704 1018 3501618484 2020795524 2124...  (4.1, 4.2]   \n",
       "...                                                  ...         ...   \n",
       "55337  11629 11704 10462 11617 3501744275 20424 35017...  (4.4, 4.5]   \n",
       "64048  273469383 20424 20422 246 1416 11867 11629 104...  (3.5, 3.6]   \n",
       "22010  273469383 21247 11867 1082283206 20422 246 101...  (4.4, 4.5]   \n",
       "40089                   11704 1018 273469383 10462 20422         NaN   \n",
       "32180  246 11867 1018 1415 1416 1524 10462 1509 11617...  (4.2, 4.3]   \n",
       "\n",
       "       predicted_average_bill  is_true_predicted  \n",
       "65841                   500.0              False  \n",
       "48882                   500.0               True  \n",
       "33711                   500.0               True  \n",
       "33544                  1500.0              False  \n",
       "35293                   500.0               True  \n",
       "...                       ...                ...  \n",
       "55337                  1500.0              False  \n",
       "64048                  1500.0              False  \n",
       "22010                  1500.0              False  \n",
       "40089                   500.0               True  \n",
       "32180                   500.0               True  \n",
       "\n",
       "[10605 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_test['is_true_predicted'] = clean_data_test['average_bill'] == clean_data_test['predicted_average_bill']\n",
    "clean_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_bill\n",
       "500.0     6608\n",
       "1000.0     700\n",
       "1500.0     217\n",
       "2000.0       0\n",
       "2500.0       0\n",
       "Name: is_true_predicted, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_test.groupby(['average_bill'])['is_true_predicted'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylrAIjCcGH7N"
   },
   "source": [
    "Для диагностики напечатайте для каждого класса тестовой выборки, сколько в нём объектов и скольким из них наш классификатор приписал правильный класс. Что вы видите?\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "    \n",
    "  Вы, вероятно, видите то, что мы стали однозначно лучше по сравнению с бейзлайном детектировать средний чек 1000 и 1500 (хотя всё равно не очень хорошо + ценой ухудшения качества на среднем чеке 500), а вот чеки 2000 и 2500 нам ну никак не даются.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ScOy7ZvGH7N"
   },
   "source": [
    "**Кстати**. А вы понимаете, почему приведённый выше пайплайн классификации был не очень удачным с точки зрения архитектуры? Почему его было бы правильнее воплотить по-другому?\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<details>\n",
    "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
    "Собственно говоря, и не было никакого пайплайна. К счастью, у нас была одна обучающая выборка, мы на ней посчитали список рубрик для modified_rubrics и радовались жизни. Но если бы нам надо было переобучать всё на новых данных, пришлось бы помнить, что их надо везде пересчитать (ведь у нас могли появиться новые рубрики с хотя бы 100 представителями). А уж никакую кросс-валидацию (кто знает - тот поймёт) с нашим подходом к делу и вовсе бы не получилось сделать без боли.\n",
    "    \n",
    "Поэтому в следующей лабораторной вы научитесь делать честные пайплайны, в которых преобразование данных, генерация фичей и обучение классификатора будут объединены в один понятный процесс, происходящий на этапе fit.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ujl3tbbGH7N"
   },
   "source": [
    "## Слишком простые и слишком сложные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QF7McCHsGH7N"
   },
   "source": [
    "Бейзлайны у нас слишком просты и потому не очень полезны в жизни. Но если сложность модели растёт бесконтрольно, то тоже получается плохо.\n",
    "\n",
    "Давайте рассмотрим конкретный пример. Создадим классификатор, использующий одновременно `rubrics_id` и `features_id`.\n",
    "\n",
    "Сделайте следующее:\n",
    "\n",
    "- для каждого объекта обучающей выборки сконкатенируйте строку `rubrics_id` с разделителем (например, буквой 'q') и содержимым `features_id`. Полученный столбец озаглавьте `modified_features`. Это не самый клёвый способ заиспользовать все фичи, но сейчас пока сойдёт. Причём на сей раз не будем выкидывать мало представленные значения (вся информация важна, не так ли?).\n",
    "- при этом для тестовой выборке заменяйте на строку `other` все конкатенации, которые не встретились в обучающей выборке.\n",
    "\n",
    "То есть элементы в этом столбце будут иметь вид `other` или `30776 30774 q 3502045032 11741 3502045016 1046...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_id</th>\n",
       "      <th>city</th>\n",
       "      <th>average_bill</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics_id</th>\n",
       "      <th>features_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65841</th>\n",
       "      <td>14385912302763770021</td>\n",
       "      <td>spb</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.748444</td>\n",
       "      <td>30776 30770 31401</td>\n",
       "      <td>11177 3501618484 10462 3501481355 1509 1416 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48882</th>\n",
       "      <td>16695436192794975203</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.793758</td>\n",
       "      <td>30771</td>\n",
       "      <td>3501744275 273469383 3501513153 11617 10462 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33711</th>\n",
       "      <td>11841431940065207518</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.606557</td>\n",
       "      <td>30771 30777</td>\n",
       "      <td>3501773763 3501744275 3501773764 3501618484 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33544</th>\n",
       "      <td>16028521499441205186</td>\n",
       "      <td>msk</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.683841</td>\n",
       "      <td>30776</td>\n",
       "      <td>3501618484 20422 1082283206 11704 11629 21247 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>12477116204055673498</td>\n",
       "      <td>spb</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.165394</td>\n",
       "      <td>30776 31401 30770</td>\n",
       "      <td>1524 246 11704 1018 3501618484 2020795524 2124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55337</th>\n",
       "      <td>9041226080397910513</td>\n",
       "      <td>msk</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>4.408108</td>\n",
       "      <td>30776</td>\n",
       "      <td>11629 11704 10462 11617 3501744275 20424 35017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64048</th>\n",
       "      <td>14998683880343589209</td>\n",
       "      <td>msk</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>30776</td>\n",
       "      <td>273469383 20424 20422 246 1416 11867 11629 104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>1621254442333414922</td>\n",
       "      <td>msk</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.402516</td>\n",
       "      <td>30776</td>\n",
       "      <td>273469383 21247 11867 1082283206 20422 246 101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40089</th>\n",
       "      <td>5620614742257813954</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30771</td>\n",
       "      <td>11704 1018 273469383 10462 20422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>11624301828012509826</td>\n",
       "      <td>spb</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>30774</td>\n",
       "      <td>246 11867 1018 1415 1416 1524 10462 1509 11617...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     org_id city  average_bill    rating         rubrics_id  \\\n",
       "65841  14385912302763770021  spb        1000.0  4.748444  30776 30770 31401   \n",
       "48882  16695436192794975203  msk         500.0  3.793758              30771   \n",
       "33711  11841431940065207518  msk         500.0  3.606557        30771 30777   \n",
       "33544  16028521499441205186  msk        2000.0  4.683841              30776   \n",
       "35293  12477116204055673498  spb         500.0  4.165394  30776 31401 30770   \n",
       "...                     ...  ...           ...       ...                ...   \n",
       "55337   9041226080397910513  msk        2500.0  4.408108              30776   \n",
       "64048  14998683880343589209  msk        1000.0  3.555556              30776   \n",
       "22010   1621254442333414922  msk        2000.0  4.402516              30776   \n",
       "40089   5620614742257813954  msk         500.0       NaN              30771   \n",
       "32180  11624301828012509826  spb         500.0  4.250000              30774   \n",
       "\n",
       "                                             features_id  \n",
       "65841  11177 3501618484 10462 3501481355 1509 1416 20...  \n",
       "48882  3501744275 273469383 3501513153 11617 10462 11...  \n",
       "33711  3501773763 3501744275 3501773764 3501618484 15...  \n",
       "33544  3501618484 20422 1082283206 11704 11629 21247 ...  \n",
       "35293  1524 246 11704 1018 3501618484 2020795524 2124...  \n",
       "...                                                  ...  \n",
       "55337  11629 11704 10462 11617 3501744275 20424 35017...  \n",
       "64048  273469383 20424 20422 246 1416 11867 11629 104...  \n",
       "22010  273469383 21247 11867 1082283206 20422 246 101...  \n",
       "40089                   11704 1018 273469383 10462 20422  \n",
       "32180  246 11867 1018 1415 1416 1524 10462 1509 11617...  \n",
       "\n",
       "[10605 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_test = clean_data_test.drop(columns=['rating_bins', 'predicted_average_bill', 'is_true_predicted'])\n",
    "clean_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_id</th>\n",
       "      <th>city</th>\n",
       "      <th>average_bill</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics_id</th>\n",
       "      <th>features_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45769</th>\n",
       "      <td>3276960721840719260</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>30770</td>\n",
       "      <td>11704 20422 1018 11177 1416 11867 10462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39061</th>\n",
       "      <td>8452997364765928283</td>\n",
       "      <td>msk</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4.442623</td>\n",
       "      <td>30774 30776</td>\n",
       "      <td>1415 3501481355 1416 11629 10462 1524 20422 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59281</th>\n",
       "      <td>14240408259222214074</td>\n",
       "      <td>spb</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.018868</td>\n",
       "      <td>30776 30774</td>\n",
       "      <td>3502045032 11741 3502045016 10462 11704 350177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51225</th>\n",
       "      <td>15114069072602161053</td>\n",
       "      <td>msk</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4.364742</td>\n",
       "      <td>31401 30776</td>\n",
       "      <td>3501513153 3501779478 3491142672 273469383 350...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29587</th>\n",
       "      <td>2730337118800634815</td>\n",
       "      <td>msk</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.698718</td>\n",
       "      <td>30770</td>\n",
       "      <td>21247 10896 3491142672 11629 3501481353 350148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64667</th>\n",
       "      <td>15641319025413596274</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.510753</td>\n",
       "      <td>30771</td>\n",
       "      <td>20424 3501744275 273469383 10462 11177 11617 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47309</th>\n",
       "      <td>2049892259403324519</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>30771</td>\n",
       "      <td>273469383 20424 11704 11629 10462 20422 1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>12224074314753892871</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30775</td>\n",
       "      <td>21247 11867 11629 1524 1509 20422 1416 1415 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48599</th>\n",
       "      <td>16581456988770474074</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>31495 30774</td>\n",
       "      <td>3491142672 20282 3501637468 11741 3501745827 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17863</th>\n",
       "      <td>11409605273003015299</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>30774</td>\n",
       "      <td>3501744275 11617 3502045032 3502045016 20424 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21531 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     org_id city  average_bill    rating   rubrics_id  \\\n",
       "45769   3276960721840719260  msk         500.0  4.500000        30770   \n",
       "39061   8452997364765928283  msk        1500.0  4.442623  30774 30776   \n",
       "59281  14240408259222214074  spb        1000.0  4.018868  30776 30774   \n",
       "51225  15114069072602161053  msk        1500.0  4.364742  31401 30776   \n",
       "29587   2730337118800634815  msk        1000.0  4.698718        30770   \n",
       "...                     ...  ...           ...       ...          ...   \n",
       "64667  15641319025413596274  msk         500.0  4.510753        30771   \n",
       "47309   2049892259403324519  msk         500.0  4.333333        30771   \n",
       "26208  12224074314753892871  msk         500.0  5.000000        30775   \n",
       "48599  16581456988770474074  msk         500.0  4.692308  31495 30774   \n",
       "17863  11409605273003015299  msk         500.0  3.222222        30774   \n",
       "\n",
       "                                             features_id  \n",
       "45769            11704 20422 1018 11177 1416 11867 10462  \n",
       "39061  1415 3501481355 1416 11629 10462 1524 20422 11...  \n",
       "59281  3502045032 11741 3502045016 10462 11704 350177...  \n",
       "51225  3501513153 3501779478 3491142672 273469383 350...  \n",
       "29587  21247 10896 3491142672 11629 3501481353 350148...  \n",
       "...                                                  ...  \n",
       "64667  20424 3501744275 273469383 10462 11177 11617 1...  \n",
       "47309       273469383 20424 11704 11629 10462 20422 1018  \n",
       "26208  21247 11867 11629 1524 1509 20422 1416 1415 10...  \n",
       "48599  3491142672 20282 3501637468 11741 3501745827 3...  \n",
       "17863  3501744275 11617 3502045032 3502045016 20424 1...  \n",
       "\n",
       "[21531 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_train = clean_data_train.drop(columns=['rating_bins'])\n",
    "clean_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_train['modified_features'] = clean_data_train['rubrics_id'] + ' q ' + clean_data_train['features_id']\n",
    "clean_data_test['modified_features'] = clean_data_test['rubrics_id'] + ' q ' + clean_data_test['features_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexMedianClassifier(ClassifierMixin):\n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()  # Создаем копию X, чтобы избежать модификаций оригинального DataFrame\n",
    "\n",
    "        X['average_bill'] = y\n",
    "        \n",
    "        # Группируем по city и modified_rubrics, считая медиану\n",
    "        self.res_dict = X.groupby(['modified_features'])['average_bill'].median().to_dict()\n",
    "        self.glob = X['average_bill'].median()\n",
    "        #print(1, self.res_dict)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.copy()  # Избегаем модификации оригинального DataFrame\n",
    "        # Применяем маппинг к rubrics_id\n",
    "        res = X['modified_features'].map(self.res_dict)\n",
    "        #print(res)\n",
    "        #print('----------------------------')\n",
    "        res.fillna(self.glob, inplace=True)\n",
    "        #print(res)\n",
    "        \"\"\"a = set(X['rubrics_id'])\n",
    "        b = set(self.rubric_mapping.keys())\n",
    "        rubrics_to_mark_as_other = a - b\n",
    "        X['modified_rubrics'] = np.where(\n",
    "            X['rubrics_id'].isin(rubrics_to_mark_as_other),\n",
    "            'other',\n",
    "            X['modified_rubrics']\n",
    "        )\n",
    "        # Вычисляем предсказание для каждой строки\n",
    "        res = X.apply(\n",
    "            lambda row: self.res_dict.get((row['city'], row['modified_rubrics']), None),\n",
    "            axis=1\n",
    "        )\"\"\"\n",
    "        return res.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 1500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 750.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 1000.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 1000.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 1500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " 500.0,\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ComplexMedianClassifier()\n",
    "clf.fit(clean_data_train, clean_data_train['average_bill'])\n",
    "clf.predict(clean_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8tNBPzVGH7O"
   },
   "source": [
    "Теперь обучите классификатор, который для заведения предсказывает медиану среднего чека по всем объектам тестовой выборки с таким же, как у него, значением `modified_features`, а если такого в обучающей выборке нет, то глобальную медиану среднего чека по всей обучающей выборке.\n",
    "\n",
    "**9. Загрузите в Контест предсказания этого классификатора на тестовой выборке**\n",
    "\n",
    "Мы ждём файла **.csv**, у которого в каждой строке будет только одно число - предсказание классификатора.\n",
    "\n",
    "Возможно, вам будет полезна библиотека ``tqdm``, позволяющая отслеживать в реальном времени, сколько времени уже крутится цикл и сколько итераций ещё осталось. Впрочем, если вы всё написали нормально, то должно работать не очень долго."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65841</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48882</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33711</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33544</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55337</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64048</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40089</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "65841  500.0\n",
       "48882  500.0\n",
       "33711  500.0\n",
       "33544  500.0\n",
       "35293  500.0\n",
       "...      ...\n",
       "55337  500.0\n",
       "64048  500.0\n",
       "22010  500.0\n",
       "40089  500.0\n",
       "32180  500.0\n",
       "\n",
       "[10605 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send = pd.DataFrame()\n",
    "send.index = clean_data_test.index\n",
    "send['pred'] = clf.predict(clean_data_test)\n",
    "send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "send.to_csv('send.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.4162067388783 0.9931928777769354 513.9898108867789 0.2010249213051401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "c:\\Users\\VIKTOR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "rmse_train = np.sqrt(mean_squared_error(clean_data_train['average_bill'], clf.predict(clean_data_train)))\n",
    "bal_acc_train = balanced_accuracy_score(clean_data_train['average_bill'], clf.predict(clean_data_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(clean_data_test['average_bill'], clf.predict(clean_data_test)))\n",
    "bal_acc_test = balanced_accuracy_score(clean_data_test['average_bill'], clf.predict(clean_data_test))\n",
    "\n",
    "print(rmse_train, bal_acc_train, rmse_test, bal_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XrswPW4GH7O"
   },
   "source": [
    "Модель, очевидно, очень сложная. Число параметров (различных категорий) в ней сопоставимо с числом объектов в обучающей выборке. А получилось ли хорошо?\n",
    "\n",
    "Давайте посчитаем RMSE и balanced_accuracy_score на обучающей и на тестовой выборках.\n",
    "\n",
    "**10. Введите их в Контест**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGDTpxFgGH7O"
   },
   "source": [
    "Налицо переобучение: на трейне метрики отличные, на тесте - вообще никакие\n",
    "\n",
    "В общем, не гонитесь за чрезмерной сложностью модели.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTU2yubYGH7O"
   },
   "source": [
    "## ML без данных что компутер без электричества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBVOCVf2GH7P"
   },
   "source": [
    "Возможно, вы смотрите на полученные выше результаты и думаете: вот если бы мы не какие-то убогие медианы предсказывали, а гоняли бы нейросети, то тут-то бы всё и получилось!\n",
    "\n",
    "Но, увы, совсем даже не всегда от счастья нас отделяет выбор хорошей модели (и стратегии обучения). Если данные не очень, то даже самая крутая модель не сработает. В этой ситуации нужно либо добывать новые фичи каким-то образом, либо собирать новые данные (увеличивать датасет), либо просто бросать задачу.\n",
    "\n",
    "Давайте посмотрим, что выжмет из наших данных одна из самых мощных моделей для табличных данных - градиентный бустинг на решающих деревьях в исполнении [CatBoost](https://catboost.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0L4UmzSGH7P"
   },
   "source": [
    "Но прежде, чем сделать fit, нам надо облагородить данные. Несмотря на то, что CatBoost отлично работает с категориальными фичами, мешок признаков из `rubrics_id` или `features_id` может ему оказаться не по зубам. Поэтому мы соберём датасет в пристойную матрицу, создав для каждого типа рубрик и фичей отдельный столбец и записав там единицы для тех объектов, у которых эта рубрика или фича имеет место.\n",
    "\n",
    "В матрице почти все элементы будут нулями. Такие матрицы считаются **разреженными** и их можно хранить гораздо эффективней, чем просто таблицей. Этим и займёмся)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJKuMtNbGH7P"
   },
   "source": [
    "Есть несколько форматов хранения разреженных матриц (многие из них реализованы в [пакете sparse библиотеки scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)), и каждый пригоден для чего-то своего.\n",
    "\n",
    "Создавать разреженную матрицу лучше в [формате COO](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_array.html#scipy.sparse.coo_array). Он предполагает, что разреженная матрица задаётся в виде трёх списков: `row`, `col`, `data`, причём каждая тройка `(row[i], col[i], data[i])` кодирует элемент со значением `data[i]`, стоящий на позиции `(row[i], col[i])`. Считается, что на позициях `(row, col)`, которые ни разу не встретились, стоят нули.\n",
    "\n",
    "Нетрудно видеть, что заполнять такую матрицу - одно удовольствие, и особенно этому помогает тот факт, что **пара `(row, col)` может встретиться несколько раз** (тогда в итоговой матрице на соответствующей позиции стоит сумма соответствующих `data[i]`). Но, с другой стороны, почти ничего другого с такой матрицей не сделаешь: произвольного доступа к элементам она не предоставляет, умножить её тоже особо ничего не умножишь. Поэтому для дальнейшего использования созданную таким образом матрицу преобразуют в один из более удобных форматов, например, [CSR (compressed sparse row)](https://scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html). Он, к примеру, хорошо подходит для умножения на вектор (потому что матрица хранится по строкам). Не будем разбирать его подробно, но можете почитать по ссылке, если интересно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hd_Sob3GH7P"
   },
   "source": [
    "Вам нужно будет превратить обучающие и тестовые данные в разреженные матрицы `sparse_data_train` и `sparse_data_test` соответственно, таким образом, что:\n",
    "\n",
    "- столбец `city` превратится в столбец из единиц и нулей (например, 1 - Москва, 0 - Питер);\n",
    "- столбец `rating` перекочует в разреженные матрицы без изменений;\n",
    "- каждый типы рубрик и каждая фича превратятся в отдельный 0-1-принак;\n",
    "\n",
    "В тестовой выборке будут фичи, которых в обучающей выборке не было. С ними можно по-разному работать, но давайте создадим дополнительную фантомную фичу `feature_other`, в которой будет то, сколько неизвестных по обучающей выборке фичей есть у данного объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_id</th>\n",
       "      <th>city</th>\n",
       "      <th>average_bill</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics_id</th>\n",
       "      <th>features_id</th>\n",
       "      <th>modified_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65841</th>\n",
       "      <td>14385912302763770021</td>\n",
       "      <td>spb</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.748444</td>\n",
       "      <td>30776 30770 31401</td>\n",
       "      <td>11177 3501618484 10462 3501481355 1509 1416 20...</td>\n",
       "      <td>30776 30770 31401 q 11177 3501618484 10462 350...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48882</th>\n",
       "      <td>16695436192794975203</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.793758</td>\n",
       "      <td>30771</td>\n",
       "      <td>3501744275 273469383 3501513153 11617 10462 11...</td>\n",
       "      <td>30771 q 3501744275 273469383 3501513153 11617 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33711</th>\n",
       "      <td>11841431940065207518</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.606557</td>\n",
       "      <td>30771 30777</td>\n",
       "      <td>3501773763 3501744275 3501773764 3501618484 15...</td>\n",
       "      <td>30771 30777 q 3501773763 3501744275 3501773764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33544</th>\n",
       "      <td>16028521499441205186</td>\n",
       "      <td>msk</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.683841</td>\n",
       "      <td>30776</td>\n",
       "      <td>3501618484 20422 1082283206 11704 11629 21247 ...</td>\n",
       "      <td>30776 q 3501618484 20422 1082283206 11704 1162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35293</th>\n",
       "      <td>12477116204055673498</td>\n",
       "      <td>spb</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.165394</td>\n",
       "      <td>30776 31401 30770</td>\n",
       "      <td>1524 246 11704 1018 3501618484 2020795524 2124...</td>\n",
       "      <td>30776 31401 30770 q 1524 246 11704 1018 350161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55337</th>\n",
       "      <td>9041226080397910513</td>\n",
       "      <td>msk</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>4.408108</td>\n",
       "      <td>30776</td>\n",
       "      <td>11629 11704 10462 11617 3501744275 20424 35017...</td>\n",
       "      <td>30776 q 11629 11704 10462 11617 3501744275 204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64048</th>\n",
       "      <td>14998683880343589209</td>\n",
       "      <td>msk</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>30776</td>\n",
       "      <td>273469383 20424 20422 246 1416 11867 11629 104...</td>\n",
       "      <td>30776 q 273469383 20424 20422 246 1416 11867 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22010</th>\n",
       "      <td>1621254442333414922</td>\n",
       "      <td>msk</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4.402516</td>\n",
       "      <td>30776</td>\n",
       "      <td>273469383 21247 11867 1082283206 20422 246 101...</td>\n",
       "      <td>30776 q 273469383 21247 11867 1082283206 20422...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40089</th>\n",
       "      <td>5620614742257813954</td>\n",
       "      <td>msk</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30771</td>\n",
       "      <td>11704 1018 273469383 10462 20422</td>\n",
       "      <td>30771 q 11704 1018 273469383 10462 20422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32180</th>\n",
       "      <td>11624301828012509826</td>\n",
       "      <td>spb</td>\n",
       "      <td>500.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>30774</td>\n",
       "      <td>246 11867 1018 1415 1416 1524 10462 1509 11617...</td>\n",
       "      <td>30774 q 246 11867 1018 1415 1416 1524 10462 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10605 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     org_id city  average_bill    rating         rubrics_id  \\\n",
       "65841  14385912302763770021  spb        1000.0  4.748444  30776 30770 31401   \n",
       "48882  16695436192794975203  msk         500.0  3.793758              30771   \n",
       "33711  11841431940065207518  msk         500.0  3.606557        30771 30777   \n",
       "33544  16028521499441205186  msk        2000.0  4.683841              30776   \n",
       "35293  12477116204055673498  spb         500.0  4.165394  30776 31401 30770   \n",
       "...                     ...  ...           ...       ...                ...   \n",
       "55337   9041226080397910513  msk        2500.0  4.408108              30776   \n",
       "64048  14998683880343589209  msk        1000.0  3.555556              30776   \n",
       "22010   1621254442333414922  msk        2000.0  4.402516              30776   \n",
       "40089   5620614742257813954  msk         500.0       NaN              30771   \n",
       "32180  11624301828012509826  spb         500.0  4.250000              30774   \n",
       "\n",
       "                                             features_id  \\\n",
       "65841  11177 3501618484 10462 3501481355 1509 1416 20...   \n",
       "48882  3501744275 273469383 3501513153 11617 10462 11...   \n",
       "33711  3501773763 3501744275 3501773764 3501618484 15...   \n",
       "33544  3501618484 20422 1082283206 11704 11629 21247 ...   \n",
       "35293  1524 246 11704 1018 3501618484 2020795524 2124...   \n",
       "...                                                  ...   \n",
       "55337  11629 11704 10462 11617 3501744275 20424 35017...   \n",
       "64048  273469383 20424 20422 246 1416 11867 11629 104...   \n",
       "22010  273469383 21247 11867 1082283206 20422 246 101...   \n",
       "40089                   11704 1018 273469383 10462 20422   \n",
       "32180  246 11867 1018 1415 1416 1524 10462 1509 11617...   \n",
       "\n",
       "                                       modified_features  \n",
       "65841  30776 30770 31401 q 11177 3501618484 10462 350...  \n",
       "48882  30771 q 3501744275 273469383 3501513153 11617 ...  \n",
       "33711  30771 30777 q 3501773763 3501744275 3501773764...  \n",
       "33544  30776 q 3501618484 20422 1082283206 11704 1162...  \n",
       "35293  30776 31401 30770 q 1524 246 11704 1018 350161...  \n",
       "...                                                  ...  \n",
       "55337  30776 q 11629 11704 10462 11617 3501744275 204...  \n",
       "64048  30776 q 273469383 20424 20422 246 1416 11867 1...  \n",
       "22010  30776 q 273469383 21247 11867 1082283206 20422...  \n",
       "40089           30771 q 11704 1018 273469383 10462 20422  \n",
       "32180  30774 q 246 11867 1018 1415 1416 1524 10462 15...  \n",
       "\n",
       "[10605 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "7-UAatGJGH7P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "# Преобразование данных city\n",
    "def process_city(data, cities_map=None):\n",
    "    if cities_map is None:\n",
    "        cities_map = {city: idx for idx, city in enumerate(data['city'].unique())}\n",
    "    city_sparse = csr_matrix(data['city'].map(cities_map).fillna(-1).astype(int).values.reshape(-1, 1))\n",
    "    return city_sparse, cities_map\n",
    "\n",
    "# Преобразование rating\n",
    "def process_rating(data):\n",
    "    return csr_matrix(data['rating'].values.reshape(-1, 1))\n",
    "\n",
    "# Преобразование features и rubrics\n",
    "def process_features_rubrics(data, unique_features=None, unique_rubrics=None):\n",
    "    if unique_features is None:\n",
    "        unique_features = set(data['features_id'].explode().unique())\n",
    "    if unique_rubrics is None:\n",
    "        unique_rubrics = set(data['rubrics_id'].explode().unique())\n",
    "    \n",
    "    # Фичи\n",
    "    features = data['features_id'].apply(lambda x: set(x))\n",
    "    features_sparse = csr_matrix([\n",
    "        [1 if f in obj_features else 0 for f in unique_features] for obj_features in features\n",
    "    ])\n",
    "    feature_other = csr_matrix([\n",
    "        [len(obj_features - unique_features)] for obj_features in features\n",
    "    ])\n",
    "    \n",
    "    # Рубрики\n",
    "    rubrics = data['rubrics_id'].apply(lambda x: set(x))\n",
    "    rubrics_sparse = csr_matrix([\n",
    "        [1 if r in obj_rubrics else 0 for r in unique_rubrics] for obj_rubrics in rubrics\n",
    "    ])\n",
    "    \n",
    "    return hstack([features_sparse, feature_other, rubrics_sparse]), unique_features, unique_rubrics\n",
    "\n",
    "# Обработка данных\n",
    "def process_data(data, cities_map=None, unique_features=None, unique_rubrics=None):\n",
    "    city_sparse, cities_map = process_city(data, cities_map)\n",
    "    rating_sparse = process_rating(data)\n",
    "    features_rubrics_sparse, unique_features, unique_rubrics = process_features_rubrics(\n",
    "        data, unique_features, unique_rubrics\n",
    "    )\n",
    "    return hstack([city_sparse, rating_sparse, features_rubrics_sparse]), cities_map, unique_features, unique_rubrics\n",
    "\n",
    "# Пример вызова\n",
    "sparse_data_train, cities_map, unique_features, unique_rubrics = process_data(clean_data_train)\n",
    "sparse_data_test, _, _, _ = process_data(clean_data_test, cities_map, unique_features, unique_rubrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFfj-1E4GH7Q"
   },
   "source": [
    "Данные готовы, и теперь можно запустить катбуст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "m2lP5NouGH7Q"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21531x20879 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50653 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "jpW6uR0oGH7Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.092536\n",
      "0:\tlearn: 1.4671709\ttotal: 159ms\tremaining: 2m 38s\n",
      "1:\tlearn: 1.3670766\ttotal: 164ms\tremaining: 1m 21s\n",
      "2:\tlearn: 1.2909334\ttotal: 177ms\tremaining: 59s\n",
      "3:\tlearn: 1.2313624\ttotal: 188ms\tremaining: 46.8s\n",
      "4:\tlearn: 1.1826790\ttotal: 200ms\tremaining: 39.8s\n",
      "5:\tlearn: 1.1433696\ttotal: 211ms\tremaining: 35s\n",
      "6:\tlearn: 1.1114025\ttotal: 216ms\tremaining: 30.7s\n",
      "7:\tlearn: 1.0842871\ttotal: 226ms\tremaining: 28s\n",
      "8:\tlearn: 1.0615809\ttotal: 233ms\tremaining: 25.7s\n",
      "9:\tlearn: 1.0422781\ttotal: 241ms\tremaining: 23.9s\n",
      "10:\tlearn: 1.0252335\ttotal: 248ms\tremaining: 22.3s\n",
      "11:\tlearn: 1.0107711\ttotal: 259ms\tremaining: 21.3s\n",
      "12:\tlearn: 0.9981021\ttotal: 269ms\tremaining: 20.4s\n",
      "13:\tlearn: 0.9871289\ttotal: 279ms\tremaining: 19.7s\n",
      "14:\tlearn: 0.9780212\ttotal: 289ms\tremaining: 19s\n",
      "15:\tlearn: 0.9694570\ttotal: 297ms\tremaining: 18.3s\n",
      "16:\tlearn: 0.9626647\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 0.9565219\ttotal: 313ms\tremaining: 17.1s\n",
      "18:\tlearn: 0.9506311\ttotal: 324ms\tremaining: 16.7s\n",
      "19:\tlearn: 0.9464052\ttotal: 328ms\tremaining: 16.1s\n",
      "20:\tlearn: 0.9426940\ttotal: 333ms\tremaining: 15.5s\n",
      "21:\tlearn: 0.9387926\ttotal: 343ms\tremaining: 15.2s\n",
      "22:\tlearn: 0.9359492\ttotal: 347ms\tremaining: 14.7s\n",
      "23:\tlearn: 0.9335995\ttotal: 352ms\tremaining: 14.3s\n",
      "24:\tlearn: 0.9309148\ttotal: 361ms\tremaining: 14.1s\n",
      "25:\tlearn: 0.9286503\ttotal: 371ms\tremaining: 13.9s\n",
      "26:\tlearn: 0.9269732\ttotal: 379ms\tremaining: 13.7s\n",
      "27:\tlearn: 0.9252062\ttotal: 389ms\tremaining: 13.5s\n",
      "28:\tlearn: 0.9236021\ttotal: 397ms\tremaining: 13.3s\n",
      "29:\tlearn: 0.9221745\ttotal: 407ms\tremaining: 13.2s\n",
      "30:\tlearn: 0.9207131\ttotal: 417ms\tremaining: 13s\n",
      "31:\tlearn: 0.9199226\ttotal: 421ms\tremaining: 12.7s\n",
      "32:\tlearn: 0.9190799\ttotal: 430ms\tremaining: 12.6s\n",
      "33:\tlearn: 0.9180950\ttotal: 439ms\tremaining: 12.5s\n",
      "34:\tlearn: 0.9174565\ttotal: 450ms\tremaining: 12.4s\n",
      "35:\tlearn: 0.9166693\ttotal: 459ms\tremaining: 12.3s\n",
      "36:\tlearn: 0.9160407\ttotal: 468ms\tremaining: 12.2s\n",
      "37:\tlearn: 0.9152355\ttotal: 477ms\tremaining: 12.1s\n",
      "38:\tlearn: 0.9145643\ttotal: 486ms\tremaining: 12s\n",
      "39:\tlearn: 0.9143358\ttotal: 490ms\tremaining: 11.8s\n",
      "40:\tlearn: 0.9136917\ttotal: 499ms\tremaining: 11.7s\n",
      "41:\tlearn: 0.9131004\ttotal: 507ms\tremaining: 11.6s\n",
      "42:\tlearn: 0.9127993\ttotal: 516ms\tremaining: 11.5s\n",
      "43:\tlearn: 0.9126538\ttotal: 520ms\tremaining: 11.3s\n",
      "44:\tlearn: 0.9122540\ttotal: 528ms\tremaining: 11.2s\n",
      "45:\tlearn: 0.9119683\ttotal: 537ms\tremaining: 11.1s\n",
      "46:\tlearn: 0.9116088\ttotal: 547ms\tremaining: 11.1s\n",
      "47:\tlearn: 0.9114102\ttotal: 554ms\tremaining: 11s\n",
      "48:\tlearn: 0.9113370\ttotal: 559ms\tremaining: 10.8s\n",
      "49:\tlearn: 0.9110167\ttotal: 569ms\tremaining: 10.8s\n",
      "50:\tlearn: 0.9109756\ttotal: 573ms\tremaining: 10.7s\n",
      "51:\tlearn: 0.9106371\ttotal: 582ms\tremaining: 10.6s\n",
      "52:\tlearn: 0.9105023\ttotal: 590ms\tremaining: 10.5s\n",
      "53:\tlearn: 0.9103685\ttotal: 599ms\tremaining: 10.5s\n",
      "54:\tlearn: 0.9100816\ttotal: 608ms\tremaining: 10.4s\n",
      "55:\tlearn: 0.9100279\ttotal: 614ms\tremaining: 10.3s\n",
      "56:\tlearn: 0.9097325\ttotal: 621ms\tremaining: 10.3s\n",
      "57:\tlearn: 0.9096521\ttotal: 628ms\tremaining: 10.2s\n",
      "58:\tlearn: 0.9094997\ttotal: 635ms\tremaining: 10.1s\n",
      "59:\tlearn: 0.9092740\ttotal: 645ms\tremaining: 10.1s\n",
      "60:\tlearn: 0.9091764\ttotal: 653ms\tremaining: 10.1s\n",
      "61:\tlearn: 0.9090652\ttotal: 663ms\tremaining: 10s\n",
      "62:\tlearn: 0.9088908\ttotal: 671ms\tremaining: 9.98s\n",
      "63:\tlearn: 0.9087164\ttotal: 681ms\tremaining: 9.96s\n",
      "64:\tlearn: 0.9084927\ttotal: 692ms\tremaining: 9.95s\n",
      "65:\tlearn: 0.9084212\ttotal: 699ms\tremaining: 9.89s\n",
      "66:\tlearn: 0.9083019\ttotal: 709ms\tremaining: 9.88s\n",
      "67:\tlearn: 0.9082032\ttotal: 718ms\tremaining: 9.84s\n",
      "68:\tlearn: 0.9080651\ttotal: 729ms\tremaining: 9.83s\n",
      "69:\tlearn: 0.9080624\ttotal: 733ms\tremaining: 9.73s\n",
      "70:\tlearn: 0.9079129\ttotal: 744ms\tremaining: 9.73s\n",
      "71:\tlearn: 0.9078317\ttotal: 752ms\tremaining: 9.69s\n",
      "72:\tlearn: 0.9076349\ttotal: 762ms\tremaining: 9.68s\n",
      "73:\tlearn: 0.9076221\ttotal: 768ms\tremaining: 9.62s\n",
      "74:\tlearn: 0.9075640\ttotal: 779ms\tremaining: 9.61s\n",
      "75:\tlearn: 0.9075416\ttotal: 785ms\tremaining: 9.55s\n",
      "76:\tlearn: 0.9075113\ttotal: 794ms\tremaining: 9.51s\n",
      "77:\tlearn: 0.9074652\ttotal: 802ms\tremaining: 9.48s\n",
      "78:\tlearn: 0.9073954\ttotal: 812ms\tremaining: 9.46s\n",
      "79:\tlearn: 0.9072827\ttotal: 821ms\tremaining: 9.44s\n",
      "80:\tlearn: 0.9072007\ttotal: 828ms\tremaining: 9.4s\n",
      "81:\tlearn: 0.9070382\ttotal: 839ms\tremaining: 9.39s\n",
      "82:\tlearn: 0.9069575\ttotal: 847ms\tremaining: 9.36s\n",
      "83:\tlearn: 0.9069462\ttotal: 855ms\tremaining: 9.32s\n",
      "84:\tlearn: 0.9068526\ttotal: 862ms\tremaining: 9.28s\n",
      "85:\tlearn: 0.9067933\ttotal: 871ms\tremaining: 9.25s\n",
      "86:\tlearn: 0.9065857\ttotal: 879ms\tremaining: 9.22s\n",
      "87:\tlearn: 0.9064828\ttotal: 888ms\tremaining: 9.2s\n",
      "88:\tlearn: 0.9064365\ttotal: 896ms\tremaining: 9.17s\n",
      "89:\tlearn: 0.9063687\ttotal: 905ms\tremaining: 9.15s\n",
      "90:\tlearn: 0.9063009\ttotal: 911ms\tremaining: 9.1s\n",
      "91:\tlearn: 0.9062465\ttotal: 919ms\tremaining: 9.07s\n",
      "92:\tlearn: 0.9061565\ttotal: 927ms\tremaining: 9.04s\n",
      "93:\tlearn: 0.9060582\ttotal: 937ms\tremaining: 9.03s\n",
      "94:\tlearn: 0.9058859\ttotal: 945ms\tremaining: 9s\n",
      "95:\tlearn: 0.9058115\ttotal: 954ms\tremaining: 8.98s\n",
      "96:\tlearn: 0.9056894\ttotal: 962ms\tremaining: 8.95s\n",
      "97:\tlearn: 0.9056342\ttotal: 970ms\tremaining: 8.93s\n",
      "98:\tlearn: 0.9055207\ttotal: 979ms\tremaining: 8.91s\n",
      "99:\tlearn: 0.9054601\ttotal: 987ms\tremaining: 8.88s\n",
      "100:\tlearn: 0.9054057\ttotal: 995ms\tremaining: 8.86s\n",
      "101:\tlearn: 0.9053215\ttotal: 1s\tremaining: 8.84s\n",
      "102:\tlearn: 0.9052410\ttotal: 1.01s\tremaining: 8.82s\n",
      "103:\tlearn: 0.9051928\ttotal: 1.02s\tremaining: 8.81s\n",
      "104:\tlearn: 0.9051222\ttotal: 1.03s\tremaining: 8.79s\n",
      "105:\tlearn: 0.9051185\ttotal: 1.03s\tremaining: 8.74s\n",
      "106:\tlearn: 0.9050304\ttotal: 1.04s\tremaining: 8.71s\n",
      "107:\tlearn: 0.9049277\ttotal: 1.05s\tremaining: 8.7s\n",
      "108:\tlearn: 0.9048232\ttotal: 1.06s\tremaining: 8.68s\n",
      "109:\tlearn: 0.9047990\ttotal: 1.07s\tremaining: 8.65s\n",
      "110:\tlearn: 0.9047231\ttotal: 1.08s\tremaining: 8.63s\n",
      "111:\tlearn: 0.9046288\ttotal: 1.09s\tremaining: 8.62s\n",
      "112:\tlearn: 0.9046201\ttotal: 1.09s\tremaining: 8.57s\n",
      "113:\tlearn: 0.9045603\ttotal: 1.1s\tremaining: 8.56s\n",
      "114:\tlearn: 0.9044298\ttotal: 1.11s\tremaining: 8.53s\n",
      "115:\tlearn: 0.9043580\ttotal: 1.12s\tremaining: 8.52s\n",
      "116:\tlearn: 0.9042414\ttotal: 1.13s\tremaining: 8.49s\n",
      "117:\tlearn: 0.9040926\ttotal: 1.13s\tremaining: 8.48s\n",
      "118:\tlearn: 0.9040051\ttotal: 1.14s\tremaining: 8.46s\n",
      "119:\tlearn: 0.9038841\ttotal: 1.15s\tremaining: 8.46s\n",
      "120:\tlearn: 0.9037858\ttotal: 1.16s\tremaining: 8.44s\n",
      "121:\tlearn: 0.9037515\ttotal: 1.17s\tremaining: 8.42s\n",
      "122:\tlearn: 0.9036798\ttotal: 1.18s\tremaining: 8.4s\n",
      "123:\tlearn: 0.9035882\ttotal: 1.19s\tremaining: 8.38s\n",
      "124:\tlearn: 0.9035038\ttotal: 1.2s\tremaining: 8.37s\n",
      "125:\tlearn: 0.9034349\ttotal: 1.2s\tremaining: 8.34s\n",
      "126:\tlearn: 0.9033455\ttotal: 1.21s\tremaining: 8.33s\n",
      "127:\tlearn: 0.9033036\ttotal: 1.22s\tremaining: 8.31s\n",
      "128:\tlearn: 0.9032005\ttotal: 1.23s\tremaining: 8.3s\n",
      "129:\tlearn: 0.9031112\ttotal: 1.24s\tremaining: 8.28s\n",
      "130:\tlearn: 0.9030230\ttotal: 1.25s\tremaining: 8.28s\n",
      "131:\tlearn: 0.9029472\ttotal: 1.26s\tremaining: 8.27s\n",
      "132:\tlearn: 0.9028422\ttotal: 1.27s\tremaining: 8.26s\n",
      "133:\tlearn: 0.9027908\ttotal: 1.28s\tremaining: 8.25s\n",
      "134:\tlearn: 0.9027328\ttotal: 1.28s\tremaining: 8.23s\n",
      "135:\tlearn: 0.9026622\ttotal: 1.29s\tremaining: 8.21s\n",
      "136:\tlearn: 0.9025914\ttotal: 1.3s\tremaining: 8.2s\n",
      "137:\tlearn: 0.9025173\ttotal: 1.31s\tremaining: 8.19s\n",
      "138:\tlearn: 0.9024403\ttotal: 1.32s\tremaining: 8.18s\n",
      "139:\tlearn: 0.9023879\ttotal: 1.33s\tremaining: 8.17s\n",
      "140:\tlearn: 0.9023238\ttotal: 1.34s\tremaining: 8.15s\n",
      "141:\tlearn: 0.9022121\ttotal: 1.35s\tremaining: 8.14s\n",
      "142:\tlearn: 0.9021068\ttotal: 1.36s\tremaining: 8.13s\n",
      "143:\tlearn: 0.9020626\ttotal: 1.36s\tremaining: 8.12s\n",
      "144:\tlearn: 0.9020022\ttotal: 1.38s\tremaining: 8.11s\n",
      "145:\tlearn: 0.9019684\ttotal: 1.38s\tremaining: 8.09s\n",
      "146:\tlearn: 0.9019128\ttotal: 1.39s\tremaining: 8.07s\n",
      "147:\tlearn: 0.9018536\ttotal: 1.4s\tremaining: 8.05s\n",
      "148:\tlearn: 0.9017193\ttotal: 1.41s\tremaining: 8.04s\n",
      "149:\tlearn: 0.9016254\ttotal: 1.42s\tremaining: 8.02s\n",
      "150:\tlearn: 0.9015287\ttotal: 1.42s\tremaining: 8.01s\n",
      "151:\tlearn: 0.9014280\ttotal: 1.43s\tremaining: 7.99s\n",
      "152:\tlearn: 0.9013431\ttotal: 1.44s\tremaining: 7.99s\n",
      "153:\tlearn: 0.9011853\ttotal: 1.45s\tremaining: 7.98s\n",
      "154:\tlearn: 0.9011147\ttotal: 1.46s\tremaining: 7.96s\n",
      "155:\tlearn: 0.9010624\ttotal: 1.47s\tremaining: 7.96s\n",
      "156:\tlearn: 0.9009104\ttotal: 1.48s\tremaining: 7.94s\n",
      "157:\tlearn: 0.9007968\ttotal: 1.49s\tremaining: 7.93s\n",
      "158:\tlearn: 0.9007116\ttotal: 1.49s\tremaining: 7.91s\n",
      "159:\tlearn: 0.9006691\ttotal: 1.5s\tremaining: 7.89s\n",
      "160:\tlearn: 0.9006093\ttotal: 1.51s\tremaining: 7.88s\n",
      "161:\tlearn: 0.9005553\ttotal: 1.52s\tremaining: 7.87s\n",
      "162:\tlearn: 0.9004868\ttotal: 1.53s\tremaining: 7.85s\n",
      "163:\tlearn: 0.9003990\ttotal: 1.54s\tremaining: 7.84s\n",
      "164:\tlearn: 0.9003099\ttotal: 1.55s\tremaining: 7.83s\n",
      "165:\tlearn: 0.9002189\ttotal: 1.55s\tremaining: 7.81s\n",
      "166:\tlearn: 0.9001411\ttotal: 1.56s\tremaining: 7.8s\n",
      "167:\tlearn: 0.9000548\ttotal: 1.57s\tremaining: 7.79s\n",
      "168:\tlearn: 0.8999457\ttotal: 1.58s\tremaining: 7.79s\n",
      "169:\tlearn: 0.8998879\ttotal: 1.59s\tremaining: 7.77s\n",
      "170:\tlearn: 0.8998176\ttotal: 1.6s\tremaining: 7.76s\n",
      "171:\tlearn: 0.8997420\ttotal: 1.61s\tremaining: 7.75s\n",
      "172:\tlearn: 0.8996285\ttotal: 1.62s\tremaining: 7.75s\n",
      "173:\tlearn: 0.8995584\ttotal: 1.63s\tremaining: 7.73s\n",
      "174:\tlearn: 0.8994687\ttotal: 1.64s\tremaining: 7.71s\n",
      "175:\tlearn: 0.8993429\ttotal: 1.64s\tremaining: 7.69s\n",
      "176:\tlearn: 0.8992964\ttotal: 1.65s\tremaining: 7.68s\n",
      "177:\tlearn: 0.8992171\ttotal: 1.66s\tremaining: 7.66s\n",
      "178:\tlearn: 0.8991577\ttotal: 1.67s\tremaining: 7.66s\n",
      "179:\tlearn: 0.8991139\ttotal: 1.68s\tremaining: 7.64s\n",
      "180:\tlearn: 0.8990350\ttotal: 1.69s\tremaining: 7.63s\n",
      "181:\tlearn: 0.8989450\ttotal: 1.69s\tremaining: 7.61s\n",
      "182:\tlearn: 0.8988116\ttotal: 1.7s\tremaining: 7.6s\n",
      "183:\tlearn: 0.8987099\ttotal: 1.71s\tremaining: 7.58s\n",
      "184:\tlearn: 0.8986360\ttotal: 1.72s\tremaining: 7.58s\n",
      "185:\tlearn: 0.8985143\ttotal: 1.73s\tremaining: 7.57s\n",
      "186:\tlearn: 0.8984282\ttotal: 1.74s\tremaining: 7.55s\n",
      "187:\tlearn: 0.8983852\ttotal: 1.75s\tremaining: 7.54s\n",
      "188:\tlearn: 0.8983142\ttotal: 1.75s\tremaining: 7.52s\n",
      "189:\tlearn: 0.8982531\ttotal: 1.76s\tremaining: 7.51s\n",
      "190:\tlearn: 0.8981692\ttotal: 1.77s\tremaining: 7.5s\n",
      "191:\tlearn: 0.8980774\ttotal: 1.78s\tremaining: 7.49s\n",
      "192:\tlearn: 0.8980233\ttotal: 1.79s\tremaining: 7.47s\n",
      "193:\tlearn: 0.8979494\ttotal: 1.79s\tremaining: 7.46s\n",
      "194:\tlearn: 0.8978954\ttotal: 1.8s\tremaining: 7.45s\n",
      "195:\tlearn: 0.8978023\ttotal: 1.81s\tremaining: 7.44s\n",
      "196:\tlearn: 0.8977362\ttotal: 1.82s\tremaining: 7.42s\n",
      "197:\tlearn: 0.8977198\ttotal: 1.83s\tremaining: 7.41s\n",
      "198:\tlearn: 0.8976495\ttotal: 1.84s\tremaining: 7.39s\n",
      "199:\tlearn: 0.8976048\ttotal: 1.85s\tremaining: 7.38s\n",
      "200:\tlearn: 0.8975506\ttotal: 1.85s\tremaining: 7.37s\n",
      "201:\tlearn: 0.8974907\ttotal: 1.86s\tremaining: 7.36s\n",
      "202:\tlearn: 0.8974561\ttotal: 1.87s\tremaining: 7.34s\n",
      "203:\tlearn: 0.8974107\ttotal: 1.88s\tremaining: 7.34s\n",
      "204:\tlearn: 0.8973287\ttotal: 1.89s\tremaining: 7.33s\n",
      "205:\tlearn: 0.8972163\ttotal: 1.9s\tremaining: 7.32s\n",
      "206:\tlearn: 0.8971766\ttotal: 1.91s\tremaining: 7.31s\n",
      "207:\tlearn: 0.8971200\ttotal: 1.92s\tremaining: 7.3s\n",
      "208:\tlearn: 0.8970783\ttotal: 1.93s\tremaining: 7.29s\n",
      "209:\tlearn: 0.8970240\ttotal: 1.93s\tremaining: 7.27s\n",
      "210:\tlearn: 0.8969733\ttotal: 1.94s\tremaining: 7.26s\n",
      "211:\tlearn: 0.8969274\ttotal: 1.95s\tremaining: 7.25s\n",
      "212:\tlearn: 0.8968840\ttotal: 1.96s\tremaining: 7.24s\n",
      "213:\tlearn: 0.8968368\ttotal: 1.97s\tremaining: 7.22s\n",
      "214:\tlearn: 0.8967749\ttotal: 1.98s\tremaining: 7.21s\n",
      "215:\tlearn: 0.8966852\ttotal: 1.98s\tremaining: 7.2s\n",
      "216:\tlearn: 0.8966248\ttotal: 1.99s\tremaining: 7.19s\n",
      "217:\tlearn: 0.8965410\ttotal: 2s\tremaining: 7.17s\n",
      "218:\tlearn: 0.8964668\ttotal: 2.01s\tremaining: 7.16s\n",
      "219:\tlearn: 0.8963991\ttotal: 2.02s\tremaining: 7.15s\n",
      "220:\tlearn: 0.8963511\ttotal: 2.03s\tremaining: 7.14s\n",
      "221:\tlearn: 0.8962959\ttotal: 2.03s\tremaining: 7.13s\n",
      "222:\tlearn: 0.8961999\ttotal: 2.04s\tremaining: 7.12s\n",
      "223:\tlearn: 0.8961279\ttotal: 2.05s\tremaining: 7.12s\n",
      "224:\tlearn: 0.8960761\ttotal: 2.07s\tremaining: 7.12s\n",
      "225:\tlearn: 0.8960237\ttotal: 2.08s\tremaining: 7.11s\n",
      "226:\tlearn: 0.8959898\ttotal: 2.08s\tremaining: 7.09s\n",
      "227:\tlearn: 0.8958996\ttotal: 2.09s\tremaining: 7.08s\n",
      "228:\tlearn: 0.8958268\ttotal: 2.1s\tremaining: 7.07s\n",
      "229:\tlearn: 0.8957741\ttotal: 2.11s\tremaining: 7.06s\n",
      "230:\tlearn: 0.8957083\ttotal: 2.12s\tremaining: 7.05s\n",
      "231:\tlearn: 0.8956777\ttotal: 2.13s\tremaining: 7.04s\n",
      "232:\tlearn: 0.8956192\ttotal: 2.13s\tremaining: 7.02s\n",
      "233:\tlearn: 0.8955672\ttotal: 2.14s\tremaining: 7.01s\n",
      "234:\tlearn: 0.8954821\ttotal: 2.15s\tremaining: 7s\n",
      "235:\tlearn: 0.8954552\ttotal: 2.16s\tremaining: 6.99s\n",
      "236:\tlearn: 0.8953916\ttotal: 2.17s\tremaining: 6.98s\n",
      "237:\tlearn: 0.8953618\ttotal: 2.18s\tremaining: 6.97s\n",
      "238:\tlearn: 0.8953074\ttotal: 2.19s\tremaining: 6.96s\n",
      "239:\tlearn: 0.8952483\ttotal: 2.19s\tremaining: 6.95s\n",
      "240:\tlearn: 0.8951464\ttotal: 2.2s\tremaining: 6.94s\n",
      "241:\tlearn: 0.8950973\ttotal: 2.21s\tremaining: 6.93s\n",
      "242:\tlearn: 0.8950242\ttotal: 2.22s\tremaining: 6.92s\n",
      "243:\tlearn: 0.8949626\ttotal: 2.23s\tremaining: 6.91s\n",
      "244:\tlearn: 0.8949132\ttotal: 2.24s\tremaining: 6.91s\n",
      "245:\tlearn: 0.8948673\ttotal: 2.25s\tremaining: 6.9s\n",
      "246:\tlearn: 0.8948186\ttotal: 2.26s\tremaining: 6.89s\n",
      "247:\tlearn: 0.8947611\ttotal: 2.27s\tremaining: 6.88s\n",
      "248:\tlearn: 0.8946964\ttotal: 2.28s\tremaining: 6.87s\n",
      "249:\tlearn: 0.8946329\ttotal: 2.29s\tremaining: 6.86s\n",
      "250:\tlearn: 0.8945700\ttotal: 2.29s\tremaining: 6.84s\n",
      "251:\tlearn: 0.8945157\ttotal: 2.3s\tremaining: 6.83s\n",
      "252:\tlearn: 0.8944400\ttotal: 2.31s\tremaining: 6.82s\n",
      "253:\tlearn: 0.8943908\ttotal: 2.32s\tremaining: 6.82s\n",
      "254:\tlearn: 0.8943461\ttotal: 2.33s\tremaining: 6.8s\n",
      "255:\tlearn: 0.8943044\ttotal: 2.34s\tremaining: 6.8s\n",
      "256:\tlearn: 0.8942345\ttotal: 2.35s\tremaining: 6.79s\n",
      "257:\tlearn: 0.8941768\ttotal: 2.35s\tremaining: 6.77s\n",
      "258:\tlearn: 0.8941352\ttotal: 2.36s\tremaining: 6.76s\n",
      "259:\tlearn: 0.8940590\ttotal: 2.37s\tremaining: 6.75s\n",
      "260:\tlearn: 0.8940114\ttotal: 2.38s\tremaining: 6.74s\n",
      "261:\tlearn: 0.8939459\ttotal: 2.39s\tremaining: 6.73s\n",
      "262:\tlearn: 0.8939063\ttotal: 2.4s\tremaining: 6.72s\n",
      "263:\tlearn: 0.8938205\ttotal: 2.41s\tremaining: 6.71s\n",
      "264:\tlearn: 0.8937629\ttotal: 2.42s\tremaining: 6.7s\n",
      "265:\tlearn: 0.8937108\ttotal: 2.42s\tremaining: 6.69s\n",
      "266:\tlearn: 0.8936676\ttotal: 2.44s\tremaining: 6.68s\n",
      "267:\tlearn: 0.8936201\ttotal: 2.44s\tremaining: 6.67s\n",
      "268:\tlearn: 0.8935796\ttotal: 2.45s\tremaining: 6.66s\n",
      "269:\tlearn: 0.8935126\ttotal: 2.46s\tremaining: 6.66s\n",
      "270:\tlearn: 0.8934716\ttotal: 2.47s\tremaining: 6.64s\n",
      "271:\tlearn: 0.8933974\ttotal: 2.48s\tremaining: 6.64s\n",
      "272:\tlearn: 0.8933615\ttotal: 2.49s\tremaining: 6.63s\n",
      "273:\tlearn: 0.8933168\ttotal: 2.5s\tremaining: 6.62s\n",
      "274:\tlearn: 0.8932600\ttotal: 2.51s\tremaining: 6.62s\n",
      "275:\tlearn: 0.8932142\ttotal: 2.52s\tremaining: 6.61s\n",
      "276:\tlearn: 0.8931645\ttotal: 2.53s\tremaining: 6.6s\n",
      "277:\tlearn: 0.8931327\ttotal: 2.54s\tremaining: 6.58s\n",
      "278:\tlearn: 0.8930917\ttotal: 2.54s\tremaining: 6.58s\n",
      "279:\tlearn: 0.8930401\ttotal: 2.55s\tremaining: 6.57s\n",
      "280:\tlearn: 0.8929702\ttotal: 2.56s\tremaining: 6.56s\n",
      "281:\tlearn: 0.8929209\ttotal: 2.57s\tremaining: 6.55s\n",
      "282:\tlearn: 0.8928586\ttotal: 2.58s\tremaining: 6.54s\n",
      "283:\tlearn: 0.8927789\ttotal: 2.59s\tremaining: 6.53s\n",
      "284:\tlearn: 0.8927123\ttotal: 2.6s\tremaining: 6.52s\n",
      "285:\tlearn: 0.8926825\ttotal: 2.61s\tremaining: 6.51s\n",
      "286:\tlearn: 0.8925833\ttotal: 2.62s\tremaining: 6.5s\n",
      "287:\tlearn: 0.8925079\ttotal: 2.63s\tremaining: 6.5s\n",
      "288:\tlearn: 0.8924688\ttotal: 2.64s\tremaining: 6.49s\n",
      "289:\tlearn: 0.8924070\ttotal: 2.65s\tremaining: 6.48s\n",
      "290:\tlearn: 0.8923905\ttotal: 2.65s\tremaining: 6.47s\n",
      "291:\tlearn: 0.8923386\ttotal: 2.66s\tremaining: 6.46s\n",
      "292:\tlearn: 0.8923052\ttotal: 2.67s\tremaining: 6.44s\n",
      "293:\tlearn: 0.8922587\ttotal: 2.68s\tremaining: 6.43s\n",
      "294:\tlearn: 0.8922199\ttotal: 2.69s\tremaining: 6.42s\n",
      "295:\tlearn: 0.8921732\ttotal: 2.7s\tremaining: 6.41s\n",
      "296:\tlearn: 0.8921024\ttotal: 2.71s\tremaining: 6.4s\n",
      "297:\tlearn: 0.8920439\ttotal: 2.71s\tremaining: 6.39s\n",
      "298:\tlearn: 0.8920000\ttotal: 2.72s\tremaining: 6.38s\n",
      "299:\tlearn: 0.8919415\ttotal: 2.73s\tremaining: 6.37s\n",
      "300:\tlearn: 0.8918967\ttotal: 2.74s\tremaining: 6.36s\n",
      "301:\tlearn: 0.8918704\ttotal: 2.75s\tremaining: 6.35s\n",
      "302:\tlearn: 0.8918026\ttotal: 2.76s\tremaining: 6.34s\n",
      "303:\tlearn: 0.8917439\ttotal: 2.77s\tremaining: 6.33s\n",
      "304:\tlearn: 0.8917034\ttotal: 2.77s\tremaining: 6.32s\n",
      "305:\tlearn: 0.8916778\ttotal: 2.78s\tremaining: 6.32s\n",
      "306:\tlearn: 0.8916401\ttotal: 2.79s\tremaining: 6.3s\n",
      "307:\tlearn: 0.8915750\ttotal: 2.8s\tremaining: 6.3s\n",
      "308:\tlearn: 0.8915307\ttotal: 2.81s\tremaining: 6.28s\n",
      "309:\tlearn: 0.8914647\ttotal: 2.82s\tremaining: 6.27s\n",
      "310:\tlearn: 0.8913940\ttotal: 2.83s\tremaining: 6.26s\n",
      "311:\tlearn: 0.8913711\ttotal: 2.83s\tremaining: 6.25s\n",
      "312:\tlearn: 0.8913361\ttotal: 2.84s\tremaining: 6.24s\n",
      "313:\tlearn: 0.8912785\ttotal: 2.85s\tremaining: 6.23s\n",
      "314:\tlearn: 0.8912207\ttotal: 2.86s\tremaining: 6.22s\n",
      "315:\tlearn: 0.8911845\ttotal: 2.87s\tremaining: 6.21s\n",
      "316:\tlearn: 0.8911287\ttotal: 2.88s\tremaining: 6.2s\n",
      "317:\tlearn: 0.8910734\ttotal: 2.89s\tremaining: 6.19s\n",
      "318:\tlearn: 0.8910242\ttotal: 2.9s\tremaining: 6.18s\n",
      "319:\tlearn: 0.8909873\ttotal: 2.9s\tremaining: 6.17s\n",
      "320:\tlearn: 0.8908889\ttotal: 2.92s\tremaining: 6.17s\n",
      "321:\tlearn: 0.8908514\ttotal: 2.92s\tremaining: 6.16s\n",
      "322:\tlearn: 0.8908240\ttotal: 2.93s\tremaining: 6.15s\n",
      "323:\tlearn: 0.8907898\ttotal: 2.94s\tremaining: 6.13s\n",
      "324:\tlearn: 0.8907476\ttotal: 2.95s\tremaining: 6.13s\n",
      "325:\tlearn: 0.8907140\ttotal: 2.96s\tremaining: 6.11s\n",
      "326:\tlearn: 0.8906575\ttotal: 2.97s\tremaining: 6.11s\n",
      "327:\tlearn: 0.8906027\ttotal: 2.97s\tremaining: 6.09s\n",
      "328:\tlearn: 0.8905627\ttotal: 2.98s\tremaining: 6.09s\n",
      "329:\tlearn: 0.8905333\ttotal: 2.99s\tremaining: 6.08s\n",
      "330:\tlearn: 0.8904500\ttotal: 3s\tremaining: 6.07s\n",
      "331:\tlearn: 0.8904108\ttotal: 3.01s\tremaining: 6.06s\n",
      "332:\tlearn: 0.8903623\ttotal: 3.02s\tremaining: 6.05s\n",
      "333:\tlearn: 0.8903036\ttotal: 3.03s\tremaining: 6.04s\n",
      "334:\tlearn: 0.8902431\ttotal: 3.04s\tremaining: 6.03s\n",
      "335:\tlearn: 0.8902012\ttotal: 3.05s\tremaining: 6.02s\n",
      "336:\tlearn: 0.8901536\ttotal: 3.06s\tremaining: 6.01s\n",
      "337:\tlearn: 0.8900777\ttotal: 3.06s\tremaining: 6s\n",
      "338:\tlearn: 0.8900391\ttotal: 3.07s\tremaining: 5.99s\n",
      "339:\tlearn: 0.8899847\ttotal: 3.08s\tremaining: 5.98s\n",
      "340:\tlearn: 0.8899418\ttotal: 3.09s\tremaining: 5.97s\n",
      "341:\tlearn: 0.8898945\ttotal: 3.1s\tremaining: 5.96s\n",
      "342:\tlearn: 0.8898572\ttotal: 3.1s\tremaining: 5.95s\n",
      "343:\tlearn: 0.8898189\ttotal: 3.12s\tremaining: 5.94s\n",
      "344:\tlearn: 0.8897732\ttotal: 3.12s\tremaining: 5.93s\n",
      "345:\tlearn: 0.8897423\ttotal: 3.13s\tremaining: 5.92s\n",
      "346:\tlearn: 0.8896871\ttotal: 3.14s\tremaining: 5.91s\n",
      "347:\tlearn: 0.8896472\ttotal: 3.15s\tremaining: 5.9s\n",
      "348:\tlearn: 0.8895845\ttotal: 3.16s\tremaining: 5.89s\n",
      "349:\tlearn: 0.8895440\ttotal: 3.17s\tremaining: 5.88s\n",
      "350:\tlearn: 0.8894764\ttotal: 3.18s\tremaining: 5.87s\n",
      "351:\tlearn: 0.8894432\ttotal: 3.18s\tremaining: 5.86s\n",
      "352:\tlearn: 0.8894211\ttotal: 3.19s\tremaining: 5.85s\n",
      "353:\tlearn: 0.8893937\ttotal: 3.2s\tremaining: 5.85s\n",
      "354:\tlearn: 0.8893392\ttotal: 3.21s\tremaining: 5.84s\n",
      "355:\tlearn: 0.8893078\ttotal: 3.22s\tremaining: 5.83s\n",
      "356:\tlearn: 0.8892347\ttotal: 3.23s\tremaining: 5.82s\n",
      "357:\tlearn: 0.8892144\ttotal: 3.24s\tremaining: 5.81s\n",
      "358:\tlearn: 0.8891363\ttotal: 3.25s\tremaining: 5.8s\n",
      "359:\tlearn: 0.8890883\ttotal: 3.26s\tremaining: 5.79s\n",
      "360:\tlearn: 0.8890676\ttotal: 3.27s\tremaining: 5.78s\n",
      "361:\tlearn: 0.8890335\ttotal: 3.27s\tremaining: 5.77s\n",
      "362:\tlearn: 0.8889937\ttotal: 3.28s\tremaining: 5.76s\n",
      "363:\tlearn: 0.8889565\ttotal: 3.29s\tremaining: 5.75s\n",
      "364:\tlearn: 0.8889228\ttotal: 3.3s\tremaining: 5.74s\n",
      "365:\tlearn: 0.8888944\ttotal: 3.31s\tremaining: 5.73s\n",
      "366:\tlearn: 0.8888616\ttotal: 3.32s\tremaining: 5.72s\n",
      "367:\tlearn: 0.8888371\ttotal: 3.33s\tremaining: 5.71s\n",
      "368:\tlearn: 0.8888183\ttotal: 3.33s\tremaining: 5.7s\n",
      "369:\tlearn: 0.8887791\ttotal: 3.34s\tremaining: 5.69s\n",
      "370:\tlearn: 0.8887548\ttotal: 3.35s\tremaining: 5.68s\n",
      "371:\tlearn: 0.8887256\ttotal: 3.36s\tremaining: 5.67s\n",
      "372:\tlearn: 0.8886751\ttotal: 3.37s\tremaining: 5.66s\n",
      "373:\tlearn: 0.8886445\ttotal: 3.38s\tremaining: 5.65s\n",
      "374:\tlearn: 0.8886051\ttotal: 3.39s\tremaining: 5.64s\n",
      "375:\tlearn: 0.8885782\ttotal: 3.4s\tremaining: 5.64s\n",
      "376:\tlearn: 0.8885330\ttotal: 3.4s\tremaining: 5.63s\n",
      "377:\tlearn: 0.8885058\ttotal: 3.41s\tremaining: 5.62s\n",
      "378:\tlearn: 0.8884606\ttotal: 3.42s\tremaining: 5.61s\n",
      "379:\tlearn: 0.8884438\ttotal: 3.43s\tremaining: 5.6s\n",
      "380:\tlearn: 0.8884002\ttotal: 3.44s\tremaining: 5.59s\n",
      "381:\tlearn: 0.8883516\ttotal: 3.45s\tremaining: 5.58s\n",
      "382:\tlearn: 0.8883317\ttotal: 3.46s\tremaining: 5.57s\n",
      "383:\tlearn: 0.8883008\ttotal: 3.46s\tremaining: 5.56s\n",
      "384:\tlearn: 0.8882611\ttotal: 3.47s\tremaining: 5.55s\n",
      "385:\tlearn: 0.8882341\ttotal: 3.48s\tremaining: 5.54s\n",
      "386:\tlearn: 0.8882071\ttotal: 3.49s\tremaining: 5.53s\n",
      "387:\tlearn: 0.8881557\ttotal: 3.5s\tremaining: 5.52s\n",
      "388:\tlearn: 0.8881314\ttotal: 3.51s\tremaining: 5.51s\n",
      "389:\tlearn: 0.8881035\ttotal: 3.52s\tremaining: 5.5s\n",
      "390:\tlearn: 0.8880620\ttotal: 3.52s\tremaining: 5.49s\n",
      "391:\tlearn: 0.8880438\ttotal: 3.53s\tremaining: 5.48s\n",
      "392:\tlearn: 0.8879689\ttotal: 3.54s\tremaining: 5.47s\n",
      "393:\tlearn: 0.8879309\ttotal: 3.55s\tremaining: 5.46s\n",
      "394:\tlearn: 0.8878967\ttotal: 3.56s\tremaining: 5.46s\n",
      "395:\tlearn: 0.8878623\ttotal: 3.57s\tremaining: 5.44s\n",
      "396:\tlearn: 0.8878255\ttotal: 3.58s\tremaining: 5.44s\n",
      "397:\tlearn: 0.8877971\ttotal: 3.59s\tremaining: 5.43s\n",
      "398:\tlearn: 0.8877626\ttotal: 3.6s\tremaining: 5.42s\n",
      "399:\tlearn: 0.8877266\ttotal: 3.6s\tremaining: 5.41s\n",
      "400:\tlearn: 0.8876746\ttotal: 3.61s\tremaining: 5.4s\n",
      "401:\tlearn: 0.8876326\ttotal: 3.62s\tremaining: 5.39s\n",
      "402:\tlearn: 0.8876113\ttotal: 3.63s\tremaining: 5.38s\n",
      "403:\tlearn: 0.8875881\ttotal: 3.64s\tremaining: 5.37s\n",
      "404:\tlearn: 0.8875551\ttotal: 3.65s\tremaining: 5.36s\n",
      "405:\tlearn: 0.8875275\ttotal: 3.66s\tremaining: 5.35s\n",
      "406:\tlearn: 0.8874764\ttotal: 3.67s\tremaining: 5.34s\n",
      "407:\tlearn: 0.8874371\ttotal: 3.67s\tremaining: 5.33s\n",
      "408:\tlearn: 0.8873947\ttotal: 3.68s\tremaining: 5.32s\n",
      "409:\tlearn: 0.8873593\ttotal: 3.69s\tremaining: 5.31s\n",
      "410:\tlearn: 0.8873072\ttotal: 3.7s\tremaining: 5.3s\n",
      "411:\tlearn: 0.8872488\ttotal: 3.71s\tremaining: 5.29s\n",
      "412:\tlearn: 0.8872009\ttotal: 3.72s\tremaining: 5.29s\n",
      "413:\tlearn: 0.8871628\ttotal: 3.73s\tremaining: 5.28s\n",
      "414:\tlearn: 0.8871391\ttotal: 3.74s\tremaining: 5.27s\n",
      "415:\tlearn: 0.8871019\ttotal: 3.75s\tremaining: 5.26s\n",
      "416:\tlearn: 0.8870666\ttotal: 3.75s\tremaining: 5.25s\n",
      "417:\tlearn: 0.8870464\ttotal: 3.76s\tremaining: 5.24s\n",
      "418:\tlearn: 0.8870196\ttotal: 3.77s\tremaining: 5.23s\n",
      "419:\tlearn: 0.8869806\ttotal: 3.78s\tremaining: 5.22s\n",
      "420:\tlearn: 0.8869528\ttotal: 3.79s\tremaining: 5.21s\n",
      "421:\tlearn: 0.8869292\ttotal: 3.8s\tremaining: 5.2s\n",
      "422:\tlearn: 0.8868907\ttotal: 3.81s\tremaining: 5.2s\n",
      "423:\tlearn: 0.8868626\ttotal: 3.82s\tremaining: 5.18s\n",
      "424:\tlearn: 0.8868255\ttotal: 3.83s\tremaining: 5.18s\n",
      "425:\tlearn: 0.8868009\ttotal: 3.83s\tremaining: 5.17s\n",
      "426:\tlearn: 0.8867576\ttotal: 3.84s\tremaining: 5.16s\n",
      "427:\tlearn: 0.8867168\ttotal: 3.85s\tremaining: 5.14s\n",
      "428:\tlearn: 0.8866880\ttotal: 3.86s\tremaining: 5.13s\n",
      "429:\tlearn: 0.8866552\ttotal: 3.87s\tremaining: 5.12s\n",
      "430:\tlearn: 0.8866087\ttotal: 3.88s\tremaining: 5.12s\n",
      "431:\tlearn: 0.8865808\ttotal: 3.88s\tremaining: 5.1s\n",
      "432:\tlearn: 0.8865541\ttotal: 3.89s\tremaining: 5.1s\n",
      "433:\tlearn: 0.8865287\ttotal: 3.9s\tremaining: 5.08s\n",
      "434:\tlearn: 0.8864901\ttotal: 3.91s\tremaining: 5.08s\n",
      "435:\tlearn: 0.8864610\ttotal: 3.92s\tremaining: 5.07s\n",
      "436:\tlearn: 0.8864285\ttotal: 3.92s\tremaining: 5.06s\n",
      "437:\tlearn: 0.8863700\ttotal: 3.93s\tremaining: 5.05s\n",
      "438:\tlearn: 0.8863269\ttotal: 3.94s\tremaining: 5.04s\n",
      "439:\tlearn: 0.8862890\ttotal: 3.95s\tremaining: 5.03s\n",
      "440:\tlearn: 0.8862556\ttotal: 3.96s\tremaining: 5.02s\n",
      "441:\tlearn: 0.8862034\ttotal: 3.97s\tremaining: 5.01s\n",
      "442:\tlearn: 0.8861661\ttotal: 3.98s\tremaining: 5s\n",
      "443:\tlearn: 0.8860833\ttotal: 3.99s\tremaining: 5s\n",
      "444:\tlearn: 0.8860680\ttotal: 4s\tremaining: 4.99s\n",
      "445:\tlearn: 0.8860370\ttotal: 4.01s\tremaining: 4.98s\n",
      "446:\tlearn: 0.8859951\ttotal: 4.02s\tremaining: 4.97s\n",
      "447:\tlearn: 0.8859449\ttotal: 4.03s\tremaining: 4.97s\n",
      "448:\tlearn: 0.8859158\ttotal: 4.04s\tremaining: 4.96s\n",
      "449:\tlearn: 0.8858809\ttotal: 4.05s\tremaining: 4.95s\n",
      "450:\tlearn: 0.8858476\ttotal: 4.06s\tremaining: 4.94s\n",
      "451:\tlearn: 0.8858154\ttotal: 4.07s\tremaining: 4.93s\n",
      "452:\tlearn: 0.8857729\ttotal: 4.08s\tremaining: 4.92s\n",
      "453:\tlearn: 0.8857420\ttotal: 4.08s\tremaining: 4.91s\n",
      "454:\tlearn: 0.8856846\ttotal: 4.09s\tremaining: 4.91s\n",
      "455:\tlearn: 0.8856481\ttotal: 4.1s\tremaining: 4.89s\n",
      "456:\tlearn: 0.8856220\ttotal: 4.11s\tremaining: 4.88s\n",
      "457:\tlearn: 0.8855892\ttotal: 4.12s\tremaining: 4.87s\n",
      "458:\tlearn: 0.8855551\ttotal: 4.13s\tremaining: 4.87s\n",
      "459:\tlearn: 0.8855039\ttotal: 4.13s\tremaining: 4.85s\n",
      "460:\tlearn: 0.8854828\ttotal: 4.14s\tremaining: 4.84s\n",
      "461:\tlearn: 0.8854190\ttotal: 4.16s\tremaining: 4.84s\n",
      "462:\tlearn: 0.8853984\ttotal: 4.17s\tremaining: 4.83s\n",
      "463:\tlearn: 0.8853364\ttotal: 4.18s\tremaining: 4.82s\n",
      "464:\tlearn: 0.8853111\ttotal: 4.18s\tremaining: 4.81s\n",
      "465:\tlearn: 0.8852836\ttotal: 4.19s\tremaining: 4.81s\n",
      "466:\tlearn: 0.8852460\ttotal: 4.2s\tremaining: 4.8s\n",
      "467:\tlearn: 0.8852047\ttotal: 4.21s\tremaining: 4.79s\n",
      "468:\tlearn: 0.8851632\ttotal: 4.22s\tremaining: 4.78s\n",
      "469:\tlearn: 0.8851170\ttotal: 4.23s\tremaining: 4.77s\n",
      "470:\tlearn: 0.8850947\ttotal: 4.24s\tremaining: 4.76s\n",
      "471:\tlearn: 0.8850679\ttotal: 4.25s\tremaining: 4.75s\n",
      "472:\tlearn: 0.8850244\ttotal: 4.25s\tremaining: 4.74s\n",
      "473:\tlearn: 0.8849744\ttotal: 4.26s\tremaining: 4.73s\n",
      "474:\tlearn: 0.8849295\ttotal: 4.27s\tremaining: 4.72s\n",
      "475:\tlearn: 0.8848978\ttotal: 4.28s\tremaining: 4.71s\n",
      "476:\tlearn: 0.8848359\ttotal: 4.29s\tremaining: 4.7s\n",
      "477:\tlearn: 0.8848169\ttotal: 4.3s\tremaining: 4.69s\n",
      "478:\tlearn: 0.8847864\ttotal: 4.31s\tremaining: 4.68s\n",
      "479:\tlearn: 0.8847685\ttotal: 4.32s\tremaining: 4.67s\n",
      "480:\tlearn: 0.8847352\ttotal: 4.33s\tremaining: 4.67s\n",
      "481:\tlearn: 0.8846955\ttotal: 4.33s\tremaining: 4.66s\n",
      "482:\tlearn: 0.8846671\ttotal: 4.34s\tremaining: 4.65s\n",
      "483:\tlearn: 0.8846338\ttotal: 4.35s\tremaining: 4.64s\n",
      "484:\tlearn: 0.8845855\ttotal: 4.36s\tremaining: 4.63s\n",
      "485:\tlearn: 0.8845555\ttotal: 4.37s\tremaining: 4.62s\n",
      "486:\tlearn: 0.8845167\ttotal: 4.38s\tremaining: 4.61s\n",
      "487:\tlearn: 0.8844937\ttotal: 4.39s\tremaining: 4.6s\n",
      "488:\tlearn: 0.8844486\ttotal: 4.39s\tremaining: 4.59s\n",
      "489:\tlearn: 0.8844319\ttotal: 4.4s\tremaining: 4.58s\n",
      "490:\tlearn: 0.8844145\ttotal: 4.41s\tremaining: 4.57s\n",
      "491:\tlearn: 0.8844014\ttotal: 4.42s\tremaining: 4.56s\n",
      "492:\tlearn: 0.8843653\ttotal: 4.43s\tremaining: 4.55s\n",
      "493:\tlearn: 0.8843401\ttotal: 4.44s\tremaining: 4.54s\n",
      "494:\tlearn: 0.8843076\ttotal: 4.44s\tremaining: 4.53s\n",
      "495:\tlearn: 0.8842780\ttotal: 4.45s\tremaining: 4.53s\n",
      "496:\tlearn: 0.8842539\ttotal: 4.46s\tremaining: 4.51s\n",
      "497:\tlearn: 0.8842111\ttotal: 4.47s\tremaining: 4.51s\n",
      "498:\tlearn: 0.8841809\ttotal: 4.48s\tremaining: 4.5s\n",
      "499:\tlearn: 0.8841237\ttotal: 4.49s\tremaining: 4.49s\n",
      "500:\tlearn: 0.8840697\ttotal: 4.5s\tremaining: 4.48s\n",
      "501:\tlearn: 0.8840283\ttotal: 4.5s\tremaining: 4.47s\n",
      "502:\tlearn: 0.8839956\ttotal: 4.52s\tremaining: 4.46s\n",
      "503:\tlearn: 0.8839403\ttotal: 4.53s\tremaining: 4.46s\n",
      "504:\tlearn: 0.8839078\ttotal: 4.54s\tremaining: 4.45s\n",
      "505:\tlearn: 0.8838616\ttotal: 4.55s\tremaining: 4.44s\n",
      "506:\tlearn: 0.8838285\ttotal: 4.56s\tremaining: 4.43s\n",
      "507:\tlearn: 0.8838070\ttotal: 4.57s\tremaining: 4.42s\n",
      "508:\tlearn: 0.8837730\ttotal: 4.58s\tremaining: 4.42s\n",
      "509:\tlearn: 0.8837359\ttotal: 4.59s\tremaining: 4.41s\n",
      "510:\tlearn: 0.8837145\ttotal: 4.59s\tremaining: 4.4s\n",
      "511:\tlearn: 0.8836876\ttotal: 4.6s\tremaining: 4.39s\n",
      "512:\tlearn: 0.8836635\ttotal: 4.61s\tremaining: 4.38s\n",
      "513:\tlearn: 0.8836242\ttotal: 4.62s\tremaining: 4.37s\n",
      "514:\tlearn: 0.8835955\ttotal: 4.63s\tremaining: 4.36s\n",
      "515:\tlearn: 0.8835684\ttotal: 4.64s\tremaining: 4.35s\n",
      "516:\tlearn: 0.8835317\ttotal: 4.65s\tremaining: 4.34s\n",
      "517:\tlearn: 0.8834915\ttotal: 4.66s\tremaining: 4.33s\n",
      "518:\tlearn: 0.8834626\ttotal: 4.67s\tremaining: 4.32s\n",
      "519:\tlearn: 0.8834195\ttotal: 4.67s\tremaining: 4.31s\n",
      "520:\tlearn: 0.8833988\ttotal: 4.68s\tremaining: 4.3s\n",
      "521:\tlearn: 0.8833686\ttotal: 4.69s\tremaining: 4.29s\n",
      "522:\tlearn: 0.8833384\ttotal: 4.7s\tremaining: 4.29s\n",
      "523:\tlearn: 0.8832886\ttotal: 4.71s\tremaining: 4.28s\n",
      "524:\tlearn: 0.8832531\ttotal: 4.72s\tremaining: 4.27s\n",
      "525:\tlearn: 0.8832079\ttotal: 4.73s\tremaining: 4.26s\n",
      "526:\tlearn: 0.8831968\ttotal: 4.74s\tremaining: 4.25s\n",
      "527:\tlearn: 0.8831633\ttotal: 4.75s\tremaining: 4.24s\n",
      "528:\tlearn: 0.8831293\ttotal: 4.75s\tremaining: 4.23s\n",
      "529:\tlearn: 0.8831023\ttotal: 4.76s\tremaining: 4.23s\n",
      "530:\tlearn: 0.8830784\ttotal: 4.78s\tremaining: 4.22s\n",
      "531:\tlearn: 0.8830526\ttotal: 4.78s\tremaining: 4.21s\n",
      "532:\tlearn: 0.8830083\ttotal: 4.79s\tremaining: 4.2s\n",
      "533:\tlearn: 0.8829778\ttotal: 4.8s\tremaining: 4.19s\n",
      "534:\tlearn: 0.8829624\ttotal: 4.81s\tremaining: 4.18s\n",
      "535:\tlearn: 0.8829412\ttotal: 4.82s\tremaining: 4.17s\n",
      "536:\tlearn: 0.8829193\ttotal: 4.82s\tremaining: 4.16s\n",
      "537:\tlearn: 0.8828754\ttotal: 4.83s\tremaining: 4.15s\n",
      "538:\tlearn: 0.8828518\ttotal: 4.84s\tremaining: 4.14s\n",
      "539:\tlearn: 0.8828359\ttotal: 4.85s\tremaining: 4.13s\n",
      "540:\tlearn: 0.8828212\ttotal: 4.86s\tremaining: 4.12s\n",
      "541:\tlearn: 0.8828176\ttotal: 4.87s\tremaining: 4.11s\n",
      "542:\tlearn: 0.8827995\ttotal: 4.88s\tremaining: 4.1s\n",
      "543:\tlearn: 0.8827618\ttotal: 4.88s\tremaining: 4.09s\n",
      "544:\tlearn: 0.8827255\ttotal: 4.9s\tremaining: 4.09s\n",
      "545:\tlearn: 0.8826852\ttotal: 4.91s\tremaining: 4.08s\n",
      "546:\tlearn: 0.8826582\ttotal: 4.92s\tremaining: 4.07s\n",
      "547:\tlearn: 0.8826360\ttotal: 4.93s\tremaining: 4.06s\n",
      "548:\tlearn: 0.8826100\ttotal: 4.94s\tremaining: 4.06s\n",
      "549:\tlearn: 0.8825565\ttotal: 4.95s\tremaining: 4.05s\n",
      "550:\tlearn: 0.8825298\ttotal: 4.96s\tremaining: 4.04s\n",
      "551:\tlearn: 0.8825073\ttotal: 4.97s\tremaining: 4.03s\n",
      "552:\tlearn: 0.8824846\ttotal: 4.98s\tremaining: 4.03s\n",
      "553:\tlearn: 0.8824601\ttotal: 4.99s\tremaining: 4.02s\n",
      "554:\tlearn: 0.8824447\ttotal: 5s\tremaining: 4.01s\n",
      "555:\tlearn: 0.8824187\ttotal: 5.01s\tremaining: 4s\n",
      "556:\tlearn: 0.8823967\ttotal: 5.02s\tremaining: 4s\n",
      "557:\tlearn: 0.8823668\ttotal: 5.04s\tremaining: 3.99s\n",
      "558:\tlearn: 0.8823376\ttotal: 5.04s\tremaining: 3.98s\n",
      "559:\tlearn: 0.8822945\ttotal: 5.06s\tremaining: 3.97s\n",
      "560:\tlearn: 0.8822664\ttotal: 5.07s\tremaining: 3.97s\n",
      "561:\tlearn: 0.8822403\ttotal: 5.08s\tremaining: 3.96s\n",
      "562:\tlearn: 0.8822032\ttotal: 5.09s\tremaining: 3.95s\n",
      "563:\tlearn: 0.8821700\ttotal: 5.11s\tremaining: 3.95s\n",
      "564:\tlearn: 0.8821312\ttotal: 5.12s\tremaining: 3.94s\n",
      "565:\tlearn: 0.8821133\ttotal: 5.13s\tremaining: 3.93s\n",
      "566:\tlearn: 0.8820815\ttotal: 5.14s\tremaining: 3.92s\n",
      "567:\tlearn: 0.8820569\ttotal: 5.15s\tremaining: 3.92s\n",
      "568:\tlearn: 0.8820271\ttotal: 5.16s\tremaining: 3.91s\n",
      "569:\tlearn: 0.8819583\ttotal: 5.18s\tremaining: 3.9s\n",
      "570:\tlearn: 0.8819490\ttotal: 5.19s\tremaining: 3.9s\n",
      "571:\tlearn: 0.8819330\ttotal: 5.2s\tremaining: 3.89s\n",
      "572:\tlearn: 0.8818914\ttotal: 5.21s\tremaining: 3.88s\n",
      "573:\tlearn: 0.8818680\ttotal: 5.22s\tremaining: 3.88s\n",
      "574:\tlearn: 0.8818423\ttotal: 5.23s\tremaining: 3.87s\n",
      "575:\tlearn: 0.8818109\ttotal: 5.24s\tremaining: 3.86s\n",
      "576:\tlearn: 0.8817930\ttotal: 5.25s\tremaining: 3.85s\n",
      "577:\tlearn: 0.8817574\ttotal: 5.27s\tremaining: 3.85s\n",
      "578:\tlearn: 0.8817220\ttotal: 5.28s\tremaining: 3.84s\n",
      "579:\tlearn: 0.8817072\ttotal: 5.29s\tremaining: 3.83s\n",
      "580:\tlearn: 0.8816896\ttotal: 5.3s\tremaining: 3.82s\n",
      "581:\tlearn: 0.8816683\ttotal: 5.31s\tremaining: 3.81s\n",
      "582:\tlearn: 0.8816395\ttotal: 5.32s\tremaining: 3.81s\n",
      "583:\tlearn: 0.8816131\ttotal: 5.33s\tremaining: 3.8s\n",
      "584:\tlearn: 0.8815934\ttotal: 5.35s\tremaining: 3.79s\n",
      "585:\tlearn: 0.8815682\ttotal: 5.35s\tremaining: 3.78s\n",
      "586:\tlearn: 0.8815512\ttotal: 5.37s\tremaining: 3.77s\n",
      "587:\tlearn: 0.8815204\ttotal: 5.38s\tremaining: 3.77s\n",
      "588:\tlearn: 0.8814947\ttotal: 5.38s\tremaining: 3.76s\n",
      "589:\tlearn: 0.8814569\ttotal: 5.39s\tremaining: 3.75s\n",
      "590:\tlearn: 0.8814184\ttotal: 5.4s\tremaining: 3.74s\n",
      "591:\tlearn: 0.8813989\ttotal: 5.41s\tremaining: 3.73s\n",
      "592:\tlearn: 0.8813550\ttotal: 5.42s\tremaining: 3.72s\n",
      "593:\tlearn: 0.8813176\ttotal: 5.43s\tremaining: 3.71s\n",
      "594:\tlearn: 0.8812838\ttotal: 5.44s\tremaining: 3.7s\n",
      "595:\tlearn: 0.8812554\ttotal: 5.45s\tremaining: 3.69s\n",
      "596:\tlearn: 0.8812304\ttotal: 5.46s\tremaining: 3.69s\n",
      "597:\tlearn: 0.8811850\ttotal: 5.47s\tremaining: 3.67s\n",
      "598:\tlearn: 0.8811627\ttotal: 5.48s\tremaining: 3.67s\n",
      "599:\tlearn: 0.8811348\ttotal: 5.48s\tremaining: 3.65s\n",
      "600:\tlearn: 0.8811092\ttotal: 5.49s\tremaining: 3.65s\n",
      "601:\tlearn: 0.8810764\ttotal: 5.5s\tremaining: 3.64s\n",
      "602:\tlearn: 0.8810501\ttotal: 5.51s\tremaining: 3.63s\n",
      "603:\tlearn: 0.8810260\ttotal: 5.52s\tremaining: 3.62s\n",
      "604:\tlearn: 0.8809824\ttotal: 5.53s\tremaining: 3.61s\n",
      "605:\tlearn: 0.8809393\ttotal: 5.54s\tremaining: 3.6s\n",
      "606:\tlearn: 0.8809150\ttotal: 5.55s\tremaining: 3.59s\n",
      "607:\tlearn: 0.8808728\ttotal: 5.56s\tremaining: 3.58s\n",
      "608:\tlearn: 0.8808512\ttotal: 5.56s\tremaining: 3.57s\n",
      "609:\tlearn: 0.8808289\ttotal: 5.58s\tremaining: 3.56s\n",
      "610:\tlearn: 0.8808043\ttotal: 5.59s\tremaining: 3.56s\n",
      "611:\tlearn: 0.8807576\ttotal: 5.59s\tremaining: 3.55s\n",
      "612:\tlearn: 0.8807165\ttotal: 5.6s\tremaining: 3.54s\n",
      "613:\tlearn: 0.8806763\ttotal: 5.61s\tremaining: 3.53s\n",
      "614:\tlearn: 0.8806615\ttotal: 5.62s\tremaining: 3.52s\n",
      "615:\tlearn: 0.8806070\ttotal: 5.63s\tremaining: 3.51s\n",
      "616:\tlearn: 0.8805553\ttotal: 5.64s\tremaining: 3.5s\n",
      "617:\tlearn: 0.8805248\ttotal: 5.65s\tremaining: 3.49s\n",
      "618:\tlearn: 0.8805099\ttotal: 5.66s\tremaining: 3.48s\n",
      "619:\tlearn: 0.8804761\ttotal: 5.67s\tremaining: 3.47s\n",
      "620:\tlearn: 0.8804609\ttotal: 5.68s\tremaining: 3.46s\n",
      "621:\tlearn: 0.8804191\ttotal: 5.68s\tremaining: 3.45s\n",
      "622:\tlearn: 0.8803938\ttotal: 5.69s\tremaining: 3.44s\n",
      "623:\tlearn: 0.8803695\ttotal: 5.7s\tremaining: 3.44s\n",
      "624:\tlearn: 0.8803394\ttotal: 5.71s\tremaining: 3.42s\n",
      "625:\tlearn: 0.8803181\ttotal: 5.72s\tremaining: 3.42s\n",
      "626:\tlearn: 0.8802956\ttotal: 5.72s\tremaining: 3.4s\n",
      "627:\tlearn: 0.8802587\ttotal: 5.74s\tremaining: 3.4s\n",
      "628:\tlearn: 0.8802368\ttotal: 5.74s\tremaining: 3.39s\n",
      "629:\tlearn: 0.8802212\ttotal: 5.75s\tremaining: 3.38s\n",
      "630:\tlearn: 0.8802061\ttotal: 5.76s\tremaining: 3.37s\n",
      "631:\tlearn: 0.8801861\ttotal: 5.77s\tremaining: 3.36s\n",
      "632:\tlearn: 0.8801704\ttotal: 5.78s\tremaining: 3.35s\n",
      "633:\tlearn: 0.8801518\ttotal: 5.79s\tremaining: 3.34s\n",
      "634:\tlearn: 0.8801343\ttotal: 5.79s\tremaining: 3.33s\n",
      "635:\tlearn: 0.8801242\ttotal: 5.8s\tremaining: 3.32s\n",
      "636:\tlearn: 0.8800834\ttotal: 5.81s\tremaining: 3.31s\n",
      "637:\tlearn: 0.8800571\ttotal: 5.82s\tremaining: 3.3s\n",
      "638:\tlearn: 0.8800362\ttotal: 5.83s\tremaining: 3.29s\n",
      "639:\tlearn: 0.8800100\ttotal: 5.84s\tremaining: 3.28s\n",
      "640:\tlearn: 0.8799736\ttotal: 5.85s\tremaining: 3.28s\n",
      "641:\tlearn: 0.8799371\ttotal: 5.86s\tremaining: 3.27s\n",
      "642:\tlearn: 0.8799092\ttotal: 5.87s\tremaining: 3.26s\n",
      "643:\tlearn: 0.8798802\ttotal: 5.88s\tremaining: 3.25s\n",
      "644:\tlearn: 0.8798345\ttotal: 5.88s\tremaining: 3.24s\n",
      "645:\tlearn: 0.8798157\ttotal: 5.89s\tremaining: 3.23s\n",
      "646:\tlearn: 0.8797728\ttotal: 5.9s\tremaining: 3.22s\n",
      "647:\tlearn: 0.8797329\ttotal: 5.91s\tremaining: 3.21s\n",
      "648:\tlearn: 0.8797151\ttotal: 5.92s\tremaining: 3.2s\n",
      "649:\tlearn: 0.8796755\ttotal: 5.93s\tremaining: 3.19s\n",
      "650:\tlearn: 0.8796177\ttotal: 5.94s\tremaining: 3.18s\n",
      "651:\tlearn: 0.8796000\ttotal: 5.95s\tremaining: 3.17s\n",
      "652:\tlearn: 0.8795818\ttotal: 5.96s\tremaining: 3.17s\n",
      "653:\tlearn: 0.8795513\ttotal: 5.97s\tremaining: 3.16s\n",
      "654:\tlearn: 0.8795360\ttotal: 5.98s\tremaining: 3.15s\n",
      "655:\tlearn: 0.8795173\ttotal: 5.99s\tremaining: 3.14s\n",
      "656:\tlearn: 0.8794995\ttotal: 6s\tremaining: 3.13s\n",
      "657:\tlearn: 0.8794887\ttotal: 6s\tremaining: 3.12s\n",
      "658:\tlearn: 0.8794629\ttotal: 6.01s\tremaining: 3.11s\n",
      "659:\tlearn: 0.8794376\ttotal: 6.02s\tremaining: 3.1s\n",
      "660:\tlearn: 0.8794146\ttotal: 6.03s\tremaining: 3.09s\n",
      "661:\tlearn: 0.8793840\ttotal: 6.04s\tremaining: 3.08s\n",
      "662:\tlearn: 0.8793569\ttotal: 6.05s\tremaining: 3.07s\n",
      "663:\tlearn: 0.8793347\ttotal: 6.06s\tremaining: 3.06s\n",
      "664:\tlearn: 0.8793140\ttotal: 6.06s\tremaining: 3.06s\n",
      "665:\tlearn: 0.8793041\ttotal: 6.07s\tremaining: 3.05s\n",
      "666:\tlearn: 0.8792807\ttotal: 6.08s\tremaining: 3.04s\n",
      "667:\tlearn: 0.8792299\ttotal: 6.09s\tremaining: 3.03s\n",
      "668:\tlearn: 0.8792114\ttotal: 6.1s\tremaining: 3.02s\n",
      "669:\tlearn: 0.8791852\ttotal: 6.11s\tremaining: 3.01s\n",
      "670:\tlearn: 0.8791689\ttotal: 6.12s\tremaining: 3s\n",
      "671:\tlearn: 0.8791310\ttotal: 6.13s\tremaining: 2.99s\n",
      "672:\tlearn: 0.8791040\ttotal: 6.14s\tremaining: 2.98s\n",
      "673:\tlearn: 0.8790635\ttotal: 6.14s\tremaining: 2.97s\n",
      "674:\tlearn: 0.8790197\ttotal: 6.15s\tremaining: 2.96s\n",
      "675:\tlearn: 0.8789981\ttotal: 6.16s\tremaining: 2.95s\n",
      "676:\tlearn: 0.8789771\ttotal: 6.17s\tremaining: 2.94s\n",
      "677:\tlearn: 0.8789607\ttotal: 6.18s\tremaining: 2.94s\n",
      "678:\tlearn: 0.8789338\ttotal: 6.19s\tremaining: 2.93s\n",
      "679:\tlearn: 0.8788902\ttotal: 6.2s\tremaining: 2.92s\n",
      "680:\tlearn: 0.8788774\ttotal: 6.21s\tremaining: 2.91s\n",
      "681:\tlearn: 0.8788555\ttotal: 6.22s\tremaining: 2.9s\n",
      "682:\tlearn: 0.8788371\ttotal: 6.22s\tremaining: 2.89s\n",
      "683:\tlearn: 0.8787953\ttotal: 6.23s\tremaining: 2.88s\n",
      "684:\tlearn: 0.8787636\ttotal: 6.24s\tremaining: 2.87s\n",
      "685:\tlearn: 0.8787468\ttotal: 6.25s\tremaining: 2.86s\n",
      "686:\tlearn: 0.8787192\ttotal: 6.26s\tremaining: 2.85s\n",
      "687:\tlearn: 0.8786956\ttotal: 6.27s\tremaining: 2.84s\n",
      "688:\tlearn: 0.8786776\ttotal: 6.28s\tremaining: 2.83s\n",
      "689:\tlearn: 0.8786552\ttotal: 6.29s\tremaining: 2.82s\n",
      "690:\tlearn: 0.8786061\ttotal: 6.29s\tremaining: 2.81s\n",
      "691:\tlearn: 0.8785913\ttotal: 6.3s\tremaining: 2.81s\n",
      "692:\tlearn: 0.8785650\ttotal: 6.31s\tremaining: 2.79s\n",
      "693:\tlearn: 0.8785455\ttotal: 6.32s\tremaining: 2.79s\n",
      "694:\tlearn: 0.8784931\ttotal: 6.33s\tremaining: 2.78s\n",
      "695:\tlearn: 0.8784721\ttotal: 6.34s\tremaining: 2.77s\n",
      "696:\tlearn: 0.8784388\ttotal: 6.35s\tremaining: 2.76s\n",
      "697:\tlearn: 0.8784214\ttotal: 6.36s\tremaining: 2.75s\n",
      "698:\tlearn: 0.8783826\ttotal: 6.37s\tremaining: 2.74s\n",
      "699:\tlearn: 0.8783591\ttotal: 6.38s\tremaining: 2.73s\n",
      "700:\tlearn: 0.8783233\ttotal: 6.39s\tremaining: 2.73s\n",
      "701:\tlearn: 0.8782851\ttotal: 6.4s\tremaining: 2.72s\n",
      "702:\tlearn: 0.8782668\ttotal: 6.41s\tremaining: 2.71s\n",
      "703:\tlearn: 0.8782471\ttotal: 6.42s\tremaining: 2.7s\n",
      "704:\tlearn: 0.8782230\ttotal: 6.42s\tremaining: 2.69s\n",
      "705:\tlearn: 0.8782018\ttotal: 6.43s\tremaining: 2.68s\n",
      "706:\tlearn: 0.8781907\ttotal: 6.44s\tremaining: 2.67s\n",
      "707:\tlearn: 0.8781752\ttotal: 6.45s\tremaining: 2.66s\n",
      "708:\tlearn: 0.8781569\ttotal: 6.46s\tremaining: 2.65s\n",
      "709:\tlearn: 0.8781350\ttotal: 6.47s\tremaining: 2.64s\n",
      "710:\tlearn: 0.8781089\ttotal: 6.47s\tremaining: 2.63s\n",
      "711:\tlearn: 0.8780913\ttotal: 6.48s\tremaining: 2.62s\n",
      "712:\tlearn: 0.8780607\ttotal: 6.49s\tremaining: 2.61s\n",
      "713:\tlearn: 0.8780270\ttotal: 6.5s\tremaining: 2.6s\n",
      "714:\tlearn: 0.8780205\ttotal: 6.51s\tremaining: 2.6s\n",
      "715:\tlearn: 0.8780049\ttotal: 6.52s\tremaining: 2.59s\n",
      "716:\tlearn: 0.8779810\ttotal: 6.53s\tremaining: 2.58s\n",
      "717:\tlearn: 0.8779501\ttotal: 6.54s\tremaining: 2.57s\n",
      "718:\tlearn: 0.8779237\ttotal: 6.55s\tremaining: 2.56s\n",
      "719:\tlearn: 0.8778983\ttotal: 6.55s\tremaining: 2.55s\n",
      "720:\tlearn: 0.8778805\ttotal: 6.57s\tremaining: 2.54s\n",
      "721:\tlearn: 0.8778353\ttotal: 6.57s\tremaining: 2.53s\n",
      "722:\tlearn: 0.8777951\ttotal: 6.58s\tremaining: 2.52s\n",
      "723:\tlearn: 0.8777745\ttotal: 6.59s\tremaining: 2.51s\n",
      "724:\tlearn: 0.8777496\ttotal: 6.6s\tremaining: 2.5s\n",
      "725:\tlearn: 0.8777013\ttotal: 6.61s\tremaining: 2.49s\n",
      "726:\tlearn: 0.8776719\ttotal: 6.62s\tremaining: 2.48s\n",
      "727:\tlearn: 0.8776449\ttotal: 6.63s\tremaining: 2.48s\n",
      "728:\tlearn: 0.8776193\ttotal: 6.64s\tremaining: 2.47s\n",
      "729:\tlearn: 0.8775960\ttotal: 6.65s\tremaining: 2.46s\n",
      "730:\tlearn: 0.8775821\ttotal: 6.66s\tremaining: 2.45s\n",
      "731:\tlearn: 0.8775457\ttotal: 6.67s\tremaining: 2.44s\n",
      "732:\tlearn: 0.8775294\ttotal: 6.68s\tremaining: 2.43s\n",
      "733:\tlearn: 0.8775036\ttotal: 6.69s\tremaining: 2.42s\n",
      "734:\tlearn: 0.8774918\ttotal: 6.7s\tremaining: 2.41s\n",
      "735:\tlearn: 0.8774773\ttotal: 6.7s\tremaining: 2.4s\n",
      "736:\tlearn: 0.8774587\ttotal: 6.71s\tremaining: 2.4s\n",
      "737:\tlearn: 0.8774403\ttotal: 6.72s\tremaining: 2.38s\n",
      "738:\tlearn: 0.8774277\ttotal: 6.73s\tremaining: 2.38s\n",
      "739:\tlearn: 0.8773913\ttotal: 6.74s\tremaining: 2.37s\n",
      "740:\tlearn: 0.8773579\ttotal: 6.75s\tremaining: 2.36s\n",
      "741:\tlearn: 0.8773254\ttotal: 6.76s\tremaining: 2.35s\n",
      "742:\tlearn: 0.8772781\ttotal: 6.76s\tremaining: 2.34s\n",
      "743:\tlearn: 0.8772248\ttotal: 6.77s\tremaining: 2.33s\n",
      "744:\tlearn: 0.8771939\ttotal: 6.78s\tremaining: 2.32s\n",
      "745:\tlearn: 0.8771789\ttotal: 6.79s\tremaining: 2.31s\n",
      "746:\tlearn: 0.8771474\ttotal: 6.8s\tremaining: 2.3s\n",
      "747:\tlearn: 0.8771112\ttotal: 6.81s\tremaining: 2.29s\n",
      "748:\tlearn: 0.8770963\ttotal: 6.82s\tremaining: 2.28s\n",
      "749:\tlearn: 0.8770831\ttotal: 6.83s\tremaining: 2.27s\n",
      "750:\tlearn: 0.8770647\ttotal: 6.83s\tremaining: 2.27s\n",
      "751:\tlearn: 0.8770525\ttotal: 6.84s\tremaining: 2.26s\n",
      "752:\tlearn: 0.8770450\ttotal: 6.85s\tremaining: 2.25s\n",
      "753:\tlearn: 0.8770133\ttotal: 6.86s\tremaining: 2.24s\n",
      "754:\tlearn: 0.8770026\ttotal: 6.87s\tremaining: 2.23s\n",
      "755:\tlearn: 0.8769797\ttotal: 6.88s\tremaining: 2.22s\n",
      "756:\tlearn: 0.8769566\ttotal: 6.88s\tremaining: 2.21s\n",
      "757:\tlearn: 0.8769449\ttotal: 6.89s\tremaining: 2.2s\n",
      "758:\tlearn: 0.8769161\ttotal: 6.9s\tremaining: 2.19s\n",
      "759:\tlearn: 0.8768827\ttotal: 6.91s\tremaining: 2.18s\n",
      "760:\tlearn: 0.8768558\ttotal: 6.92s\tremaining: 2.17s\n",
      "761:\tlearn: 0.8768259\ttotal: 6.93s\tremaining: 2.16s\n",
      "762:\tlearn: 0.8768009\ttotal: 6.94s\tremaining: 2.15s\n",
      "763:\tlearn: 0.8767903\ttotal: 6.95s\tremaining: 2.15s\n",
      "764:\tlearn: 0.8767666\ttotal: 6.96s\tremaining: 2.14s\n",
      "765:\tlearn: 0.8767342\ttotal: 6.97s\tremaining: 2.13s\n",
      "766:\tlearn: 0.8767067\ttotal: 6.97s\tremaining: 2.12s\n",
      "767:\tlearn: 0.8766794\ttotal: 6.98s\tremaining: 2.11s\n",
      "768:\tlearn: 0.8766628\ttotal: 6.99s\tremaining: 2.1s\n",
      "769:\tlearn: 0.8766403\ttotal: 7s\tremaining: 2.09s\n",
      "770:\tlearn: 0.8766195\ttotal: 7.01s\tremaining: 2.08s\n",
      "771:\tlearn: 0.8765885\ttotal: 7.02s\tremaining: 2.07s\n",
      "772:\tlearn: 0.8765754\ttotal: 7.03s\tremaining: 2.06s\n",
      "773:\tlearn: 0.8765547\ttotal: 7.03s\tremaining: 2.05s\n",
      "774:\tlearn: 0.8765294\ttotal: 7.04s\tremaining: 2.04s\n",
      "775:\tlearn: 0.8765014\ttotal: 7.05s\tremaining: 2.04s\n",
      "776:\tlearn: 0.8764885\ttotal: 7.06s\tremaining: 2.02s\n",
      "777:\tlearn: 0.8764566\ttotal: 7.07s\tremaining: 2.02s\n",
      "778:\tlearn: 0.8764384\ttotal: 7.08s\tremaining: 2.01s\n",
      "779:\tlearn: 0.8764144\ttotal: 7.09s\tremaining: 2s\n",
      "780:\tlearn: 0.8763894\ttotal: 7.09s\tremaining: 1.99s\n",
      "781:\tlearn: 0.8763711\ttotal: 7.1s\tremaining: 1.98s\n",
      "782:\tlearn: 0.8763462\ttotal: 7.11s\tremaining: 1.97s\n",
      "783:\tlearn: 0.8763126\ttotal: 7.12s\tremaining: 1.96s\n",
      "784:\tlearn: 0.8762857\ttotal: 7.13s\tremaining: 1.95s\n",
      "785:\tlearn: 0.8762530\ttotal: 7.14s\tremaining: 1.94s\n",
      "786:\tlearn: 0.8762354\ttotal: 7.15s\tremaining: 1.94s\n",
      "787:\tlearn: 0.8762127\ttotal: 7.16s\tremaining: 1.93s\n",
      "788:\tlearn: 0.8761838\ttotal: 7.17s\tremaining: 1.92s\n",
      "789:\tlearn: 0.8761694\ttotal: 7.17s\tremaining: 1.91s\n",
      "790:\tlearn: 0.8761537\ttotal: 7.18s\tremaining: 1.9s\n",
      "791:\tlearn: 0.8761406\ttotal: 7.19s\tremaining: 1.89s\n",
      "792:\tlearn: 0.8761187\ttotal: 7.2s\tremaining: 1.88s\n",
      "793:\tlearn: 0.8761089\ttotal: 7.21s\tremaining: 1.87s\n",
      "794:\tlearn: 0.8760898\ttotal: 7.22s\tremaining: 1.86s\n",
      "795:\tlearn: 0.8760756\ttotal: 7.23s\tremaining: 1.85s\n",
      "796:\tlearn: 0.8760533\ttotal: 7.23s\tremaining: 1.84s\n",
      "797:\tlearn: 0.8760384\ttotal: 7.24s\tremaining: 1.83s\n",
      "798:\tlearn: 0.8760219\ttotal: 7.25s\tremaining: 1.82s\n",
      "799:\tlearn: 0.8760075\ttotal: 7.26s\tremaining: 1.81s\n",
      "800:\tlearn: 0.8759991\ttotal: 7.27s\tremaining: 1.81s\n",
      "801:\tlearn: 0.8759807\ttotal: 7.28s\tremaining: 1.8s\n",
      "802:\tlearn: 0.8759653\ttotal: 7.29s\tremaining: 1.79s\n",
      "803:\tlearn: 0.8759587\ttotal: 7.29s\tremaining: 1.78s\n",
      "804:\tlearn: 0.8759372\ttotal: 7.3s\tremaining: 1.77s\n",
      "805:\tlearn: 0.8759229\ttotal: 7.31s\tremaining: 1.76s\n",
      "806:\tlearn: 0.8758985\ttotal: 7.32s\tremaining: 1.75s\n",
      "807:\tlearn: 0.8758596\ttotal: 7.33s\tremaining: 1.74s\n",
      "808:\tlearn: 0.8758469\ttotal: 7.34s\tremaining: 1.73s\n",
      "809:\tlearn: 0.8758295\ttotal: 7.35s\tremaining: 1.72s\n",
      "810:\tlearn: 0.8758057\ttotal: 7.36s\tremaining: 1.72s\n",
      "811:\tlearn: 0.8757814\ttotal: 7.37s\tremaining: 1.71s\n",
      "812:\tlearn: 0.8757693\ttotal: 7.43s\tremaining: 1.71s\n",
      "813:\tlearn: 0.8757544\ttotal: 7.44s\tremaining: 1.7s\n",
      "814:\tlearn: 0.8757266\ttotal: 7.44s\tremaining: 1.69s\n",
      "815:\tlearn: 0.8757137\ttotal: 7.45s\tremaining: 1.68s\n",
      "816:\tlearn: 0.8756818\ttotal: 7.46s\tremaining: 1.67s\n",
      "817:\tlearn: 0.8756450\ttotal: 7.47s\tremaining: 1.66s\n",
      "818:\tlearn: 0.8756353\ttotal: 7.49s\tremaining: 1.66s\n",
      "819:\tlearn: 0.8756108\ttotal: 7.5s\tremaining: 1.65s\n",
      "820:\tlearn: 0.8755950\ttotal: 7.51s\tremaining: 1.64s\n",
      "821:\tlearn: 0.8755720\ttotal: 7.52s\tremaining: 1.63s\n",
      "822:\tlearn: 0.8755570\ttotal: 7.53s\tremaining: 1.62s\n",
      "823:\tlearn: 0.8755312\ttotal: 7.54s\tremaining: 1.61s\n",
      "824:\tlearn: 0.8755063\ttotal: 7.54s\tremaining: 1.6s\n",
      "825:\tlearn: 0.8754852\ttotal: 7.55s\tremaining: 1.59s\n",
      "826:\tlearn: 0.8754678\ttotal: 7.56s\tremaining: 1.58s\n",
      "827:\tlearn: 0.8754573\ttotal: 7.57s\tremaining: 1.57s\n",
      "828:\tlearn: 0.8754505\ttotal: 7.58s\tremaining: 1.56s\n",
      "829:\tlearn: 0.8754266\ttotal: 7.59s\tremaining: 1.55s\n",
      "830:\tlearn: 0.8753830\ttotal: 7.59s\tremaining: 1.54s\n",
      "831:\tlearn: 0.8753490\ttotal: 7.6s\tremaining: 1.53s\n",
      "832:\tlearn: 0.8753346\ttotal: 7.61s\tremaining: 1.53s\n",
      "833:\tlearn: 0.8752919\ttotal: 7.62s\tremaining: 1.52s\n",
      "834:\tlearn: 0.8752622\ttotal: 7.63s\tremaining: 1.51s\n",
      "835:\tlearn: 0.8752347\ttotal: 7.64s\tremaining: 1.5s\n",
      "836:\tlearn: 0.8752207\ttotal: 7.65s\tremaining: 1.49s\n",
      "837:\tlearn: 0.8751978\ttotal: 7.66s\tremaining: 1.48s\n",
      "838:\tlearn: 0.8751892\ttotal: 7.67s\tremaining: 1.47s\n",
      "839:\tlearn: 0.8751794\ttotal: 7.67s\tremaining: 1.46s\n",
      "840:\tlearn: 0.8751687\ttotal: 7.68s\tremaining: 1.45s\n",
      "841:\tlearn: 0.8751574\ttotal: 7.69s\tremaining: 1.44s\n",
      "842:\tlearn: 0.8751405\ttotal: 7.7s\tremaining: 1.43s\n",
      "843:\tlearn: 0.8751247\ttotal: 7.71s\tremaining: 1.43s\n",
      "844:\tlearn: 0.8750954\ttotal: 7.72s\tremaining: 1.42s\n",
      "845:\tlearn: 0.8750654\ttotal: 7.73s\tremaining: 1.41s\n",
      "846:\tlearn: 0.8750325\ttotal: 7.74s\tremaining: 1.4s\n",
      "847:\tlearn: 0.8750149\ttotal: 7.74s\tremaining: 1.39s\n",
      "848:\tlearn: 0.8749917\ttotal: 7.75s\tremaining: 1.38s\n",
      "849:\tlearn: 0.8749696\ttotal: 7.76s\tremaining: 1.37s\n",
      "850:\tlearn: 0.8749527\ttotal: 7.77s\tremaining: 1.36s\n",
      "851:\tlearn: 0.8749366\ttotal: 7.78s\tremaining: 1.35s\n",
      "852:\tlearn: 0.8749034\ttotal: 7.78s\tremaining: 1.34s\n",
      "853:\tlearn: 0.8748851\ttotal: 7.79s\tremaining: 1.33s\n",
      "854:\tlearn: 0.8748732\ttotal: 7.8s\tremaining: 1.32s\n",
      "855:\tlearn: 0.8748538\ttotal: 7.81s\tremaining: 1.31s\n",
      "856:\tlearn: 0.8748373\ttotal: 7.82s\tremaining: 1.3s\n",
      "857:\tlearn: 0.8748224\ttotal: 7.83s\tremaining: 1.29s\n",
      "858:\tlearn: 0.8748051\ttotal: 7.84s\tremaining: 1.29s\n",
      "859:\tlearn: 0.8747824\ttotal: 7.85s\tremaining: 1.28s\n",
      "860:\tlearn: 0.8747563\ttotal: 7.86s\tremaining: 1.27s\n",
      "861:\tlearn: 0.8747358\ttotal: 7.87s\tremaining: 1.26s\n",
      "862:\tlearn: 0.8747104\ttotal: 7.87s\tremaining: 1.25s\n",
      "863:\tlearn: 0.8746965\ttotal: 7.88s\tremaining: 1.24s\n",
      "864:\tlearn: 0.8746842\ttotal: 7.89s\tremaining: 1.23s\n",
      "865:\tlearn: 0.8746703\ttotal: 7.9s\tremaining: 1.22s\n",
      "866:\tlearn: 0.8746548\ttotal: 7.91s\tremaining: 1.21s\n",
      "867:\tlearn: 0.8746404\ttotal: 7.92s\tremaining: 1.2s\n",
      "868:\tlearn: 0.8746053\ttotal: 7.93s\tremaining: 1.2s\n",
      "869:\tlearn: 0.8745777\ttotal: 7.94s\tremaining: 1.19s\n",
      "870:\tlearn: 0.8745670\ttotal: 7.95s\tremaining: 1.18s\n",
      "871:\tlearn: 0.8745549\ttotal: 7.96s\tremaining: 1.17s\n",
      "872:\tlearn: 0.8745442\ttotal: 7.97s\tremaining: 1.16s\n",
      "873:\tlearn: 0.8745181\ttotal: 7.98s\tremaining: 1.15s\n",
      "874:\tlearn: 0.8745049\ttotal: 7.99s\tremaining: 1.14s\n",
      "875:\tlearn: 0.8744871\ttotal: 8s\tremaining: 1.13s\n",
      "876:\tlearn: 0.8744585\ttotal: 8.01s\tremaining: 1.12s\n",
      "877:\tlearn: 0.8744449\ttotal: 8.02s\tremaining: 1.11s\n",
      "878:\tlearn: 0.8744128\ttotal: 8.03s\tremaining: 1.1s\n",
      "879:\tlearn: 0.8743996\ttotal: 8.04s\tremaining: 1.1s\n",
      "880:\tlearn: 0.8743715\ttotal: 8.05s\tremaining: 1.09s\n",
      "881:\tlearn: 0.8743449\ttotal: 8.06s\tremaining: 1.08s\n",
      "882:\tlearn: 0.8743302\ttotal: 8.07s\tremaining: 1.07s\n",
      "883:\tlearn: 0.8743139\ttotal: 8.08s\tremaining: 1.06s\n",
      "884:\tlearn: 0.8742902\ttotal: 8.09s\tremaining: 1.05s\n",
      "885:\tlearn: 0.8742543\ttotal: 8.1s\tremaining: 1.04s\n",
      "886:\tlearn: 0.8742324\ttotal: 8.11s\tremaining: 1.03s\n",
      "887:\tlearn: 0.8742204\ttotal: 8.12s\tremaining: 1.02s\n",
      "888:\tlearn: 0.8742098\ttotal: 8.13s\tremaining: 1.01s\n",
      "889:\tlearn: 0.8742004\ttotal: 8.14s\tremaining: 1s\n",
      "890:\tlearn: 0.8741828\ttotal: 8.15s\tremaining: 997ms\n",
      "891:\tlearn: 0.8741712\ttotal: 8.16s\tremaining: 988ms\n",
      "892:\tlearn: 0.8741390\ttotal: 8.16s\tremaining: 978ms\n",
      "893:\tlearn: 0.8741218\ttotal: 8.18s\tremaining: 969ms\n",
      "894:\tlearn: 0.8740988\ttotal: 8.19s\tremaining: 960ms\n",
      "895:\tlearn: 0.8740893\ttotal: 8.2s\tremaining: 951ms\n",
      "896:\tlearn: 0.8740740\ttotal: 8.21s\tremaining: 942ms\n",
      "897:\tlearn: 0.8740612\ttotal: 8.21s\tremaining: 933ms\n",
      "898:\tlearn: 0.8740450\ttotal: 8.22s\tremaining: 924ms\n",
      "899:\tlearn: 0.8740062\ttotal: 8.23s\tremaining: 915ms\n",
      "900:\tlearn: 0.8739744\ttotal: 8.24s\tremaining: 906ms\n",
      "901:\tlearn: 0.8739644\ttotal: 8.25s\tremaining: 897ms\n",
      "902:\tlearn: 0.8739421\ttotal: 8.26s\tremaining: 887ms\n",
      "903:\tlearn: 0.8739305\ttotal: 8.27s\tremaining: 878ms\n",
      "904:\tlearn: 0.8739114\ttotal: 8.28s\tremaining: 869ms\n",
      "905:\tlearn: 0.8738959\ttotal: 8.29s\tremaining: 860ms\n",
      "906:\tlearn: 0.8738685\ttotal: 8.3s\tremaining: 851ms\n",
      "907:\tlearn: 0.8738466\ttotal: 8.31s\tremaining: 842ms\n",
      "908:\tlearn: 0.8738357\ttotal: 8.32s\tremaining: 833ms\n",
      "909:\tlearn: 0.8738197\ttotal: 8.32s\tremaining: 823ms\n",
      "910:\tlearn: 0.8738110\ttotal: 8.33s\tremaining: 814ms\n",
      "911:\tlearn: 0.8737899\ttotal: 8.34s\tremaining: 805ms\n",
      "912:\tlearn: 0.8737747\ttotal: 8.35s\tremaining: 796ms\n",
      "913:\tlearn: 0.8737634\ttotal: 8.36s\tremaining: 787ms\n",
      "914:\tlearn: 0.8737312\ttotal: 8.37s\tremaining: 777ms\n",
      "915:\tlearn: 0.8737087\ttotal: 8.38s\tremaining: 768ms\n",
      "916:\tlearn: 0.8736851\ttotal: 8.39s\tremaining: 759ms\n",
      "917:\tlearn: 0.8736608\ttotal: 8.4s\tremaining: 750ms\n",
      "918:\tlearn: 0.8736385\ttotal: 8.4s\tremaining: 741ms\n",
      "919:\tlearn: 0.8736171\ttotal: 8.41s\tremaining: 732ms\n",
      "920:\tlearn: 0.8735994\ttotal: 8.42s\tremaining: 722ms\n",
      "921:\tlearn: 0.8735825\ttotal: 8.43s\tremaining: 713ms\n",
      "922:\tlearn: 0.8735505\ttotal: 8.44s\tremaining: 704ms\n",
      "923:\tlearn: 0.8735352\ttotal: 8.45s\tremaining: 695ms\n",
      "924:\tlearn: 0.8735234\ttotal: 8.46s\tremaining: 686ms\n",
      "925:\tlearn: 0.8734959\ttotal: 8.46s\tremaining: 677ms\n",
      "926:\tlearn: 0.8734715\ttotal: 8.47s\tremaining: 667ms\n",
      "927:\tlearn: 0.8734558\ttotal: 8.48s\tremaining: 658ms\n",
      "928:\tlearn: 0.8734441\ttotal: 8.49s\tremaining: 649ms\n",
      "929:\tlearn: 0.8734301\ttotal: 8.5s\tremaining: 640ms\n",
      "930:\tlearn: 0.8734140\ttotal: 8.51s\tremaining: 631ms\n",
      "931:\tlearn: 0.8733909\ttotal: 8.52s\tremaining: 621ms\n",
      "932:\tlearn: 0.8733818\ttotal: 8.53s\tremaining: 612ms\n",
      "933:\tlearn: 0.8733621\ttotal: 8.53s\tremaining: 603ms\n",
      "934:\tlearn: 0.8733359\ttotal: 8.54s\tremaining: 594ms\n",
      "935:\tlearn: 0.8733228\ttotal: 8.55s\tremaining: 585ms\n",
      "936:\tlearn: 0.8732953\ttotal: 8.56s\tremaining: 576ms\n",
      "937:\tlearn: 0.8732647\ttotal: 8.57s\tremaining: 566ms\n",
      "938:\tlearn: 0.8732505\ttotal: 8.58s\tremaining: 557ms\n",
      "939:\tlearn: 0.8732402\ttotal: 8.59s\tremaining: 548ms\n",
      "940:\tlearn: 0.8732232\ttotal: 8.6s\tremaining: 539ms\n",
      "941:\tlearn: 0.8732089\ttotal: 8.61s\tremaining: 530ms\n",
      "942:\tlearn: 0.8731977\ttotal: 8.61s\tremaining: 521ms\n",
      "943:\tlearn: 0.8731769\ttotal: 8.62s\tremaining: 512ms\n",
      "944:\tlearn: 0.8731675\ttotal: 8.63s\tremaining: 502ms\n",
      "945:\tlearn: 0.8731512\ttotal: 8.64s\tremaining: 493ms\n",
      "946:\tlearn: 0.8731342\ttotal: 8.65s\tremaining: 484ms\n",
      "947:\tlearn: 0.8731123\ttotal: 8.66s\tremaining: 475ms\n",
      "948:\tlearn: 0.8731008\ttotal: 8.66s\tremaining: 466ms\n",
      "949:\tlearn: 0.8730820\ttotal: 8.68s\tremaining: 457ms\n",
      "950:\tlearn: 0.8730624\ttotal: 8.68s\tremaining: 447ms\n",
      "951:\tlearn: 0.8730455\ttotal: 8.69s\tremaining: 438ms\n",
      "952:\tlearn: 0.8730163\ttotal: 8.7s\tremaining: 429ms\n",
      "953:\tlearn: 0.8730066\ttotal: 8.71s\tremaining: 420ms\n",
      "954:\tlearn: 0.8729949\ttotal: 8.72s\tremaining: 411ms\n",
      "955:\tlearn: 0.8729615\ttotal: 8.73s\tremaining: 402ms\n",
      "956:\tlearn: 0.8729464\ttotal: 8.73s\tremaining: 393ms\n",
      "957:\tlearn: 0.8729342\ttotal: 8.74s\tremaining: 383ms\n",
      "958:\tlearn: 0.8729120\ttotal: 8.75s\tremaining: 374ms\n",
      "959:\tlearn: 0.8728943\ttotal: 8.76s\tremaining: 365ms\n",
      "960:\tlearn: 0.8728755\ttotal: 8.77s\tremaining: 356ms\n",
      "961:\tlearn: 0.8728599\ttotal: 8.78s\tremaining: 347ms\n",
      "962:\tlearn: 0.8728454\ttotal: 8.79s\tremaining: 338ms\n",
      "963:\tlearn: 0.8728235\ttotal: 8.8s\tremaining: 329ms\n",
      "964:\tlearn: 0.8728073\ttotal: 8.81s\tremaining: 319ms\n",
      "965:\tlearn: 0.8727931\ttotal: 8.82s\tremaining: 310ms\n",
      "966:\tlearn: 0.8727604\ttotal: 8.82s\tremaining: 301ms\n",
      "967:\tlearn: 0.8727517\ttotal: 8.84s\tremaining: 292ms\n",
      "968:\tlearn: 0.8727382\ttotal: 8.84s\tremaining: 283ms\n",
      "969:\tlearn: 0.8727151\ttotal: 8.85s\tremaining: 274ms\n",
      "970:\tlearn: 0.8726922\ttotal: 8.86s\tremaining: 265ms\n",
      "971:\tlearn: 0.8726753\ttotal: 8.87s\tremaining: 256ms\n",
      "972:\tlearn: 0.8726599\ttotal: 8.88s\tremaining: 246ms\n",
      "973:\tlearn: 0.8726394\ttotal: 8.89s\tremaining: 237ms\n",
      "974:\tlearn: 0.8726296\ttotal: 8.9s\tremaining: 228ms\n",
      "975:\tlearn: 0.8726195\ttotal: 8.9s\tremaining: 219ms\n",
      "976:\tlearn: 0.8726073\ttotal: 8.91s\tremaining: 210ms\n",
      "977:\tlearn: 0.8725713\ttotal: 8.92s\tremaining: 201ms\n",
      "978:\tlearn: 0.8725408\ttotal: 8.93s\tremaining: 192ms\n",
      "979:\tlearn: 0.8725163\ttotal: 8.94s\tremaining: 182ms\n",
      "980:\tlearn: 0.8724903\ttotal: 8.95s\tremaining: 173ms\n",
      "981:\tlearn: 0.8724728\ttotal: 8.96s\tremaining: 164ms\n",
      "982:\tlearn: 0.8724538\ttotal: 8.97s\tremaining: 155ms\n",
      "983:\tlearn: 0.8724267\ttotal: 8.97s\tremaining: 146ms\n",
      "984:\tlearn: 0.8724084\ttotal: 8.98s\tremaining: 137ms\n",
      "985:\tlearn: 0.8723915\ttotal: 8.99s\tremaining: 128ms\n",
      "986:\tlearn: 0.8723639\ttotal: 9s\tremaining: 119ms\n",
      "987:\tlearn: 0.8723458\ttotal: 9.01s\tremaining: 109ms\n",
      "988:\tlearn: 0.8723360\ttotal: 9.02s\tremaining: 100ms\n",
      "989:\tlearn: 0.8723161\ttotal: 9.03s\tremaining: 91.2ms\n",
      "990:\tlearn: 0.8722860\ttotal: 9.04s\tremaining: 82.1ms\n",
      "991:\tlearn: 0.8722715\ttotal: 9.05s\tremaining: 73ms\n",
      "992:\tlearn: 0.8722558\ttotal: 9.06s\tremaining: 63.9ms\n",
      "993:\tlearn: 0.8722394\ttotal: 9.07s\tremaining: 54.7ms\n",
      "994:\tlearn: 0.8722247\ttotal: 9.08s\tremaining: 45.6ms\n",
      "995:\tlearn: 0.8722043\ttotal: 9.09s\tremaining: 36.5ms\n",
      "996:\tlearn: 0.8721635\ttotal: 9.1s\tremaining: 27.4ms\n",
      "997:\tlearn: 0.8721499\ttotal: 9.1s\tremaining: 18.2ms\n",
      "998:\tlearn: 0.8721366\ttotal: 9.11s\tremaining: 9.12ms\n",
      "999:\tlearn: 0.8721020\ttotal: 9.12s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b401218490>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <USE IT!>\n",
    "clf = CatBoostClassifier()\n",
    "clf.fit(sparse_data_train, clean_data_train['average_bill'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBOpZY9BGH7Q"
   },
   "source": [
    "**11. Пришлите в Контест balanced_accuracy_score на тестовой выборке, округлённый до двух знаков после запятой**. Стало ли сильно лучше от того, что мы воспользовались таким крутым классификатором?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0     10598\n",
       "1500.0        5\n",
       "1000.0        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(clf.predict(sparse_data_test).flatten()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65841    1000.0\n",
       "48882     500.0\n",
       "33711     500.0\n",
       "33544    2000.0\n",
       "35293     500.0\n",
       "          ...  \n",
       "55337    2500.0\n",
       "64048    1000.0\n",
       "22010    2000.0\n",
       "40089     500.0\n",
       "32180     500.0\n",
       "Name: average_bill, Length: 10605, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data_test['average_bill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1998371335504886"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(clean_data_test['average_bill'].to_list(), clf.predict(sparse_data_test).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
